{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d52a58d",
   "metadata": {},
   "source": [
    "# Astana Mobility GPS Dataset (No-Timestamp) Exploratory Analysis & Mapping\n",
    "\n",
    "This notebook performs privacy-preserving exploratory geospatial analysis for a GPS mobility dataset (Astana, Kazakhstan) **without timestamps**.\n",
    "Limitations: No temporal ordering beyond original file row sequence; can't compute durations, dwell times, speeds-over-ground validation, or ETA-like metrics.\n",
    "Focus: hotspots, start/end clusters, OD corridors, sample routes, anomaly cues.\n",
    "All outputs aggregated with k-anonymity (k>=20). Raw trajectories only shown for a masked 5-trip sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b76175f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Install step skipped. Set install_cmd=True to attempt installs.\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------\n",
    "# 0. (Optional) Environment Setup - Run if libraries missing\n",
    "# -------------------------------------------------------------\n",
    "# Adjust as needed; avoids network calls if already installed.\n",
    "# NOTE: Some environments disallow installs inside notebooks.\n",
    "# You can skip this cell if packages are present.\n",
    "# Python 3.11 targeted.\n",
    "install_cmd = False  # set True to attempt pip install\n",
    "required_packages = [\n",
    "    'pandas','numpy','matplotlib','geopandas','shapely','h3','pydeck','folium',\n",
    "    'scikit-learn','geopy'\n",
    "]\n",
    "optional_packages = ['datashader','similaritymeasures','traj-dist','haversine']\n",
    "if install_cmd:\n",
    "    import sys, subprocess\n",
    "    for pkg in required_packages + optional_packages:\n",
    "        try:\n",
    "            __import__(pkg.split('-')[0].replace('-', '_'))\n",
    "        except Exception:\n",
    "            print(f'Installing {pkg} ...')\n",
    "            subprocess.run([sys.executable,'-m','pip','install',pkg])\n",
    "else:\n",
    "    print('Install step skipped. Set install_cmd=True to attempt installs.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c47225b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration saved to outputs/config_snapshot.json (updated with DP_SMOOTH_TOL_DEG)\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------\n",
    "# 1. Parameters & Configuration (re-added)\n",
    "# -------------------------------------------------------------\n",
    "import os, json, random, hashlib, warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "DATA_PATH = 'geo_locations_astana_hackathon.csv'\n",
    "OUTPUT_DIR = 'outputs'\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "BBOX = {\n",
    "    'min_lat': 50.5, 'max_lat': 51.8,\n",
    "    'min_lng': 70.5, 'max_lng': 72.0\n",
    "}\n",
    "\n",
    "H3_RES_LIST = [7,8,9]\n",
    "PRIMARY_HEAT_RES = 8\n",
    "K_ANON = 20\n",
    "SAMPLE_N_TRIPS = 5\n",
    "TOP_K_OD = 5\n",
    "ROUTE_SAMPLE_PER_OD = 15\n",
    "DP_TOLERANCE_DEG = 0.0005  # ~55m simplification\n",
    "# New: 20m smoothing tolerance in degrees (approx): 20m / 111320 â‰ˆ 0.00018\n",
    "DP_SMOOTH_TOL_DEG = 20.0 / 111320.0\n",
    "STOP_SPEED_THRESHOLD = None\n",
    "STOP_CLUSTER_EPS_M = 60  # original, may be overridden by new stop logic\n",
    "STOP_CLUSTER_MIN_SAMPLES = 10  # original, replaced later\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "ROUGHNESS_Z_THRESHOLD = 2.5\n",
    "HEADING_VAR_Z_THRESHOLD = 2.5\n",
    "\n",
    "# Build CONFIG with only JSON-serializable values; stringify the rest defensively\n",
    "from collections.abc import Mapping\n",
    "\n",
    "def _to_jsonable(x):\n",
    "    try:\n",
    "        json.dumps(x)\n",
    "        return x\n",
    "    except TypeError:\n",
    "        return str(x)\n",
    "\n",
    "CONFIG = {k: _to_jsonable(v) for k,v in globals().items() if k.isupper()}\n",
    "with open(os.path.join(OUTPUT_DIR,'config_snapshot.json'),'w') as f:\n",
    "    json.dump(CONFIG, f, indent=2)\n",
    "print('Configuration saved to outputs/config_snapshot.json (updated with DP_SMOOTH_TOL_DEG)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bd396ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pydeck: True, folium: True, datashader: True, similarity: True\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------\n",
    "# 2. Imports & Optional Libraries + H3 Wrappers\n",
    "# -------------------------------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from shapely.geometry import Point, LineString\n",
    "import geopandas as gpd\n",
    "try:\n",
    "    import h3\n",
    "except ImportError as e:\n",
    "    raise ImportError('h3 library required. Install via pip install h3.') from e\n",
    "\n",
    "# --- H3 API compatibility and wrapper functions ---\n",
    "if not hasattr(h3, 'geo_to_h3') and hasattr(h3, 'latlng_to_cell'):\n",
    "    h3.geo_to_h3 = h3.latlng_to_cell  # type: ignore\n",
    "if not hasattr(h3, 'h3_to_geo') and hasattr(h3, 'cell_to_latlng'):\n",
    "    h3.h3_to_geo = h3.cell_to_latlng  # type: ignore\n",
    "if not hasattr(h3, 'h3_to_geo_boundary') and hasattr(h3, 'cell_to_boundary'):\n",
    "    def _boundary_adapter(cell, geo_json=True):\n",
    "        return h3.cell_to_boundary(cell, geo_json=geo_json)\n",
    "    h3.h3_to_geo_boundary = _boundary_adapter  # type: ignore\n",
    "\n",
    "def h3_cell_index(lat, lng, res):\n",
    "    if hasattr(h3, 'geo_to_h3'):\n",
    "        return h3.geo_to_h3(lat, lng, res)\n",
    "    if hasattr(h3, 'latlng_to_cell'):\n",
    "        return h3.latlng_to_cell(lat, lng, res)\n",
    "    raise AttributeError('No valid H3 indexing function found.')\n",
    "\n",
    "def h3_cell_center(cell):\n",
    "    if hasattr(h3, 'h3_to_geo'):\n",
    "        return h3.h3_to_geo(cell)\n",
    "    if hasattr(h3, 'cell_to_latlng'):\n",
    "        return h3.cell_to_latlng(cell)\n",
    "    raise AttributeError('No valid H3 center function found.')\n",
    "\n",
    "def h3_cell_boundary(cell):\n",
    "    if hasattr(h3, 'h3_to_geo_boundary'):\n",
    "        return h3.h3_to_geo_boundary(cell, geo_json=True)\n",
    "    if hasattr(h3, 'cell_to_boundary'):\n",
    "        return h3.cell_to_boundary(cell, geo_json=True)\n",
    "    raise AttributeError('No valid H3 boundary function found.')\n",
    "\n",
    "try:\n",
    "    import pydeck as pdk\n",
    "    HAS_PYDECK = True\n",
    "except Exception:\n",
    "    HAS_PYDECK = False\n",
    "\n",
    "try:\n",
    "    import folium\n",
    "    HAS_FOLIUM = True\n",
    "except Exception:\n",
    "    HAS_FOLIUM = False\n",
    "\n",
    "try:\n",
    "    import datashader as ds, datashader.transfer_functions as tf\n",
    "    from datashader.utils import lnglat_to_meters\n",
    "    HAS_DATASHADER = True\n",
    "except Exception:\n",
    "    HAS_DATASHADER = False\n",
    "\n",
    "# Distance utilities\n",
    "try:\n",
    "    from geopy.distance import geodesic\n",
    "except Exception:\n",
    "    geodesic = None\n",
    "\n",
    "try:\n",
    "    import similaritymeasures\n",
    "    HAS_SIMILARITY = True\n",
    "except Exception:\n",
    "    HAS_SIMILARITY = False\n",
    "\n",
    "try:\n",
    "    from sklearn.cluster import DBSCAN\n",
    "except Exception as e:\n",
    "    raise ImportError('scikit-learn required for DBSCAN. Install scikit-learn.') from e\n",
    "\n",
    "print(f'pydeck: {HAS_PYDECK}, folium: {HAS_FOLIUM}, datashader: {HAS_DATASHADER}, similarity: {HAS_SIMILARITY}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2b81bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions ready (with H3 compatibility).\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------\n",
    "# 3. Helper Functions\n",
    "# -------------------------------------------------------------\n",
    "EARTH_RADIUS_M = 6371008.8\n",
    "\n",
    "# Confirm H3 compatibility functions exist (defensive re-check)\n",
    "if not hasattr(h3, 'geo_to_h3') and hasattr(h3, 'latlng_to_cell'):\n",
    "    h3.geo_to_h3 = h3.latlng_to_cell  # type: ignore\n",
    "if not hasattr(h3, 'h3_to_geo') and hasattr(h3, 'cell_to_latlng'):\n",
    "    h3.h3_to_geo = h3.cell_to_latlng  # type: ignore\n",
    "if not hasattr(h3, 'h3_to_geo_boundary') and hasattr(h3, 'cell_to_boundary'):\n",
    "    def _boundary_adapter(cell, geo_json=True):\n",
    "        return h3.cell_to_boundary(cell, geo_json=geo_json)\n",
    "    h3.h3_to_geo_boundary = _boundary_adapter  # type: ignore\n",
    "\n",
    "def normalize_bearing(b):\n",
    "    if pd.isna(b): return np.nan\n",
    "    b = b % 360.0\n",
    "    if b < 0: b += 360.0\n",
    "    return b\n",
    "\n",
    "def haversine_km(lat1, lon1, lat2, lon2):\n",
    "    # vectorized friendly (expects scalars here)\n",
    "    dlat = math.radians(lat2 - lat1)\n",
    "    dlon = math.radians(lon2 - lon1)\n",
    "    a = math.sin(dlat/2)**2 + math.cos(math.radians(lat1))*math.cos(math.radians(lat2))*math.sin(dlon/2)**2\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1-a))\n",
    "    return (EARTH_RADIUS_M * c)/1000.0\n",
    "\n",
    "def line_length_km(coords):\n",
    "    if len(coords) < 2: return 0.0\n",
    "    return sum(haversine_km(coords[i][1], coords[i][0], coords[i+1][1], coords[i+1][0]) for i in range(len(coords)-1))\n",
    "\n",
    "def simplify_linestring(coords, tolerance=DP_TOLERANCE_DEG):\n",
    "    if len(coords) < 3: return coords\n",
    "    ls = LineString(coords)\n",
    "    simp = ls.simplify(tolerance, preserve_topology=False)\n",
    "    return list(simp.coords)\n",
    "\n",
    "def heading_variance(bearings):\n",
    "    b = [normalize_bearing(x) for x in bearings if not pd.isna(x)]\n",
    "    if len(b) == 0: return np.nan\n",
    "    return float(np.var(b))\n",
    "\n",
    "def trajectory_roughness(coords):\n",
    "    # sum of absolute turn angles divided by length km\n",
    "    if len(coords) < 3: return 0.0\n",
    "    def bearing(p1, p2):\n",
    "        lat1, lon1 = math.radians(p1[1]), math.radians(p1[0])\n",
    "        lat2, lon2 = math.radians(p2[1]), math.radians(p2[0])\n",
    "        dlon = lon2 - lon1\n",
    "        y = math.sin(dlon) * math.cos(lat2)\n",
    "        x = math.cos(lat1)*math.cos(lat2)*math.cos(dlon) + math.sin(lat1)*math.sin(lat2)\n",
    "        brng = math.degrees(math.atan2(y, x))\n",
    "        return (brng + 360) % 360\n",
    "    bearings = [bearing(coords[i], coords[i+1]) for i in range(len(coords)-1)]\n",
    "    turns = [abs(((bearings[i+1]-bearings[i]+180)%360)-180) for i in range(len(bearings)-1)]\n",
    "    total_turn = sum(turns)\n",
    "    length_km = line_length_km(coords)\n",
    "    if length_km == 0: return 0.0\n",
    "    return total_turn / length_km\n",
    "\n",
    "def mask_id(raw_id):\n",
    "    h = hashlib.sha1(str(raw_id).encode()).hexdigest()[:10]\n",
    "    return f'id_{h}'\n",
    "\n",
    "def k_suppress(df, count_col, k=K_ANON):\n",
    "    return df[df[count_col] >= k].copy()\n",
    "\n",
    "def h3_cell_polygon(lat, lng, res):\n",
    "    cid = h3.geo_to_h3(lat, lng, res)\n",
    "    boundary = h3.h3_to_geo_boundary(cid, geo_json=True)\n",
    "    return cid, boundary\n",
    "\n",
    "def frechet_distance(c1, c2):\n",
    "    if not HAS_SIMILARITY:\n",
    "        return None\n",
    "    # similaritymeasures expects Nx2 arrays (x,y). We'll treat lon=x, lat=y.\n",
    "    a = np.array([[p[0], p[1]] for p in c1])\n",
    "    b = np.array([[p[0], p[1]] for p in c2])\n",
    "    try:\n",
    "        return similaritymeasures.frechet_dist(a, b)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def pick_median_route(route_list):\n",
    "    # route_list: list of coordinate sequences. If Frechet available, choose route minimizing avg dist. Else fallback heuristic length median.\n",
    "    if len(route_list) == 0:\n",
    "        return []\n",
    "    if HAS_SIMILARITY and len(route_list) > 1:\n",
    "        dists_matrix = []\n",
    "        for i, r1 in enumerate(route_list):\n",
    "            row = []\n",
    "            for j, r2 in enumerate(route_list):\n",
    "                if i == j:\n",
    "                    row.append(0.0)\n",
    "                else:\n",
    "                    fd = frechet_distance(r1, r2)\n",
    "                    fd = fd if fd is not None else 0.0\n",
    "                    row.append(fd)\n",
    "            dists_matrix.append(row)\n",
    "        avg_dists = [np.mean(row) for row in dists_matrix]\n",
    "        idx = int(np.argmin(avg_dists))\n",
    "        return route_list[idx]\n",
    "    # Fallback: pick route with median number of points (representative simplicity).\n",
    "    lengths = [len(r) for r in route_list]\n",
    "    med_len = np.median(lengths)\n",
    "    idx = min(range(len(route_list)), key=lambda i: abs(lengths[i]-med_len))\n",
    "    return route_list[idx]\n",
    "\n",
    "print('Helper functions ready (with H3 compatibility).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a04dec54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1262687 rows.\n",
      "Dropped 0 rows with NA critical fields.\n",
      "Out-of-bounds rows removed: 0\n",
      "Duplicates removed: 72465\n",
      "         randomized_id        lat        lng         alt        spd  \\\n",
      "0  7637058049336049989  51.095460  71.427530  350.531020   0.206810   \n",
      "1  1259981924615926140  51.098200  71.412950  348.801610   0.000000   \n",
      "2  1259981924615926140  51.098460  71.412120  349.273880   4.345010   \n",
      "3  7180852955221959108  51.089779  71.428469  314.000000  14.326102   \n",
      "4 -6683155579225977143  51.088782  71.417462  325.300018   0.000602   \n",
      "\n",
      "          azm  \n",
      "0   13.601680  \n",
      "1  265.677000  \n",
      "2  307.245300  \n",
      "3  192.123672  \n",
      "4    0.000000  \n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------\n",
    "# 4. Load CSV & Schema Checks\n",
    "# -------------------------------------------------------------\n",
    "expected_cols = ['randomized_id','lat','lng','alt','spd','azm']\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(f'Loaded {len(df)} rows.')\n",
    "missing_cols = [c for c in expected_cols if c not in df.columns]\n",
    "if missing_cols:\n",
    "    raise ValueError(f'Missing required columns: {missing_cols}')\n",
    "df = df[expected_cols].copy()\n",
    "# Dtypes\n",
    "for c in ['lat','lng','alt','spd','azm']:\n",
    "    df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "\n",
    "before_na = len(df)\n",
    "df.dropna(subset=['randomized_id','lat','lng'], inplace=True)\n",
    "print(f'Dropped {before_na - len(df)} rows with NA critical fields.')\n",
    "before_bounds = len(df)\n",
    "mask_bbox = (df['lat']>=BBOX['min_lat']) & (df['lat']<=BBOX['max_lat']) & (df['lng']>=BBOX['min_lng']) & (df['lng']<=BBOX['max_lng'])\n",
    "df = df[mask_bbox].copy()\n",
    "print(f'Out-of-bounds rows removed: {before_bounds - len(df)}')\n",
    "# Duplicates\n",
    "before_dup = len(df)\n",
    "df.drop_duplicates(inplace=True)\n",
    "print(f'Duplicates removed: {before_dup - len(df)}')\n",
    "if len(df)==0:\n",
    "    raise ValueError('No data after filtering.')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75dfd145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved distributions plot to outputs\\fig_distributions.png\n",
      "             count        mean         std    min         25%         50%  \\\n",
      "spd      1190222.0    7.216874    5.894857   -1.0    1.187060    6.781900   \n",
      "alt      1190222.0  326.870034   18.609871 -191.4  317.400024  318.834709   \n",
      "bearing  1190222.0  135.603353  109.994888    0.0   13.033230  106.285740   \n",
      "\n",
      "                75%         max  \n",
      "spd       12.409584   84.469543  \n",
      "alt      347.700012  931.599280  \n",
      "bearing  219.706889  359.999969  \n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------\n",
    "# 5. Sequence Index & Basic Stats\n",
    "# -------------------------------------------------------------\n",
    "# Add sequence index per randomized_id preserving original order\n",
    "df['row_order'] = np.arange(len(df))\n",
    "df.sort_values(['randomized_id','row_order'], inplace=True)\n",
    "df['seq_idx'] = df.groupby('randomized_id').cumcount()\n",
    "\n",
    "# Normalize bearings\n",
    "df['bearing'] = df['azm'].apply(normalize_bearing)\n",
    "# Speed & altitude distributions\n",
    "fig, axes = plt.subplots(1,3, figsize=(15,4))\n",
    "df['spd'].dropna().hist(ax=axes[0], bins=40)\n",
    "axes[0].set_title('Speed Distribution')\n",
    "df['alt'].dropna().hist(ax=axes[1], bins=40, color='orange')\n",
    "axes[1].set_title('Altitude Distribution')\n",
    "df['bearing'].dropna().hist(ax=axes[2], bins=36, color='green')\n",
    "axes[2].set_title('Bearing Distribution')\n",
    "plt.tight_layout()\n",
    "fig_path = os.path.join(OUTPUT_DIR,'fig_distributions.png')\n",
    "plt.savefig(fig_path, dpi=150)\n",
    "plt.close(fig)\n",
    "print(f'Saved distributions plot to {fig_path}')\n",
    "print(df[['spd','alt','bearing']].describe().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "593fa13c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         randomized_id                                           geometry  \\\n",
      "0 -9221304899272910788  LINESTRING (71.42236 51.08296, 71.42254 51.083...   \n",
      "1 -9217374206810770265  LINESTRING (71.40246 51.08895, 71.40672 51.100...   \n",
      "2 -9214548556609186054  LINESTRING (71.42192 51.07942, 71.42517 51.078...   \n",
      "3 -9214033164510198912  LINESTRING (71.40579 51.09854, 71.40448 51.098...   \n",
      "4 -9212938812549517684  LINESTRING (71.41194 51.0977, 71.41729 51.0969...   \n",
      "\n",
      "                                 geometry_simplified  \\\n",
      "0  LINESTRING (71.4223554 51.0829583, 71.4194807 ...   \n",
      "1  LINESTRING (71.4024592 51.0889499, 71.4067199 ...   \n",
      "2  LINESTRING (71.4219152 51.0794236, 71.4269576 ...   \n",
      "3  LINESTRING (71.4057889 51.0985433, 71.4044781 ...   \n",
      "4  LINESTRING (71.4119383 51.0977033, 71.4172933 ...   \n",
      "\n",
      "                             geometry_simplified_20m  num_points  \\\n",
      "0  LINESTRING (71.4223554 51.0829583, 71.4225399 ...         209   \n",
      "1  LINESTRING (71.4024592 51.0889499, 71.4067199 ...          53   \n",
      "2  LINESTRING (71.4219152 51.0794236, 71.4269576 ...          30   \n",
      "3  LINESTRING (71.4057889 51.0985433, 71.4044781 ...          93   \n",
      "4  LINESTRING (71.4119383 51.0977033, 71.4172933 ...         276   \n",
      "\n",
      "   num_points_simplified  num_points_simplified_20m  length_km_est  \n",
      "0                    136                        154     130.020940  \n",
      "1                      6                          6      34.348924  \n",
      "2                     20                         23       6.712419  \n",
      "3                     36                         51      51.912318  \n",
      "4                    226                        239     207.408486  \n",
      "Trajectories built: 6635 (with dual simplifications)\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------\n",
    "# 6. GeoDataFrame & Trajectory Construction (Raw + Simplified)\n",
    "# -------------------------------------------------------------\n",
    "gdf = gpd.GeoDataFrame(df.copy(), geometry=[Point(xy) for xy in zip(df['lng'], df['lat'])], crs='EPSG:4326')\n",
    "\n",
    "# Build per-trip trajectories (LineString) in file order\n",
    "trip_geoms = []\n",
    "for tid, grp in gdf.groupby('randomized_id'):\n",
    "    coords = list(zip(grp['lng'].values, grp['lat'].values))\n",
    "    if len(coords) < 2: continue\n",
    "    ls = LineString(coords)\n",
    "    simp_coords = simplify_linestring(coords, tolerance=DP_TOLERANCE_DEG)\n",
    "    ls_simp = LineString(simp_coords)\n",
    "    # Additional 20m smoothing simplification\n",
    "    ls_simp20_coords = simplify_linestring(coords, tolerance=DP_SMOOTH_TOL_DEG)\n",
    "    ls_simp20 = LineString(ls_simp20_coords) if len(ls_simp20_coords) >= 2 else ls_simp\n",
    "    trip_geoms.append({\n",
    "        'randomized_id': tid,\n",
    "        'geometry': ls,\n",
    "        'geometry_simplified': ls_simp,\n",
    "        'geometry_simplified_20m': ls_simp20,\n",
    "        'num_points': len(coords),\n",
    "        'num_points_simplified': len(simp_coords),\n",
    "        'num_points_simplified_20m': len(ls_simp20_coords)\n",
    "    })\n",
    "trip_gdf = gpd.GeoDataFrame(trip_geoms, crs='EPSG:4326')\n",
    "trip_gdf['length_km_est'] = trip_gdf['geometry'].apply(lambda g: line_length_km(list(g.coords)))\n",
    "print(trip_gdf.head())\n",
    "print(f'Trajectories built: {len(trip_gdf)} (with dual simplifications)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d29123ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H3 aggregated. Suppressed cells (%): 2.20. Public cells saved -> outputs/h3_aggregates.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "h3_index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "point_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "unique_trips",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "resolution",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "suppressed",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "color_scale",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "6e9281bb-48b2-4195-aea6-728643d866fa",
       "rows": [
        [
         "0",
         "872153806ffffff",
         "498609",
         "5141",
         "7",
         "False",
         "1.0"
        ],
        [
         "1",
         "872153815ffffff",
         "8537",
         "959",
         "7",
         "False",
         "0.017121632381284734"
        ],
        [
         "2",
         "872153831ffffff",
         "340259",
         "4396",
         "7",
         "False",
         "0.6824164826547455"
        ],
        [
         "3",
         "872153833ffffff",
         "342817",
         "4058",
         "7",
         "False",
         "0.687546755072612"
        ],
        [
         "4",
         "8821538061fffff",
         "40462",
         "1948",
         "8",
         "False",
         "0.0811497586285045"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>h3_index</th>\n",
       "      <th>point_count</th>\n",
       "      <th>unique_trips</th>\n",
       "      <th>resolution</th>\n",
       "      <th>suppressed</th>\n",
       "      <th>color_scale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>872153806ffffff</td>\n",
       "      <td>498609</td>\n",
       "      <td>5141</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>872153815ffffff</td>\n",
       "      <td>8537</td>\n",
       "      <td>959</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>0.017122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>872153831ffffff</td>\n",
       "      <td>340259</td>\n",
       "      <td>4396</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>0.682416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>872153833ffffff</td>\n",
       "      <td>342817</td>\n",
       "      <td>4058</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>0.687547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8821538061fffff</td>\n",
       "      <td>40462</td>\n",
       "      <td>1948</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>0.081150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          h3_index  point_count  unique_trips  resolution  suppressed  \\\n",
       "0  872153806ffffff       498609          5141           7       False   \n",
       "1  872153815ffffff         8537           959           7       False   \n",
       "2  872153831ffffff       340259          4396           7       False   \n",
       "3  872153833ffffff       342817          4058           7       False   \n",
       "4  8821538061fffff        40462          1948           8       False   \n",
       "\n",
       "   color_scale  \n",
       "0     1.000000  \n",
       "1     0.017122  \n",
       "2     0.682416  \n",
       "3     0.687547  \n",
       "4     0.081150  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -------------------------------------------------------------\n",
    "# 7. H3 Aggregations (Counts & Unique Trips)\n",
    "# -------------------------------------------------------------\n",
    "# Using unified wrapper h3_cell_index for compatibility.\n",
    "\n",
    "h3_records = []\n",
    "for res in H3_RES_LIST:\n",
    "    cids = [h3_cell_index(lat, lng, res) for lat, lng in zip(gdf['lat'].values, gdf['lng'].values)]\n",
    "    gdf[f'h3_{res}'] = cids\n",
    "    agg = gdf.groupby(f'h3_{res}').agg(\n",
    "        point_count=('randomized_id','size'),\n",
    "        unique_trips=('randomized_id','nunique')\n",
    "    ).reset_index().rename(columns={f'h3_{res}':'h3_index'})\n",
    "    agg['resolution'] = res\n",
    "    h3_records.append(agg)\n",
    "\n",
    "h3_all = pd.concat(h3_records, ignore_index=True)\n",
    "h3_all['suppressed'] = h3_all['point_count'] < K_ANON\n",
    "suppressed_pct = 100.0 * h3_all['suppressed'].mean()\n",
    "h3_public = h3_all[~h3_all['suppressed']].copy()\n",
    "# Precompute color scaling reference for later visualization if needed\n",
    "h3_public['color_scale'] = (h3_public['point_count'] / h3_public['point_count'].max()).clip(0,1)\n",
    "\n",
    "h3_all.to_csv(os.path.join(OUTPUT_DIR,'h3_aggregates_raw.csv'), index=False)\n",
    "h3_public.to_csv(os.path.join(OUTPUT_DIR,'h3_aggregates.csv'), index=False)\n",
    "print(f'H3 aggregated. Suppressed cells (%): {suppressed_pct:.2f}. Public cells saved -> outputs/h3_aggregates.csv')\n",
    "h3_public.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b289e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OD table saved (filtered & suppressed) -> outputs/od_public.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "randomized_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "start_cell",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "end_cell",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "start_lat",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "start_lng",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "end_lat",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "end_lng",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "d6ad3909-1c61-4cf1-8d53-a3f8eaf820a5",
       "rows": [
        [
         "0",
         "-9221304899272910788",
         "8821538333fffff",
         "8821538317fffff",
         "51.0829583",
         "71.4223554",
         "51.0949961",
         "71.4162713"
        ],
        [
         "1",
         "-9217374206810770265",
         "882153833bfffff",
         "8821538331fffff",
         "51.0889499",
         "71.4024592",
         "51.0821034",
         "71.4000536"
        ],
        [
         "2",
         "-9214548556609186054",
         "8821538333fffff",
         "8821538333fffff",
         "51.0794236",
         "71.4219152",
         "51.0795122",
         "71.4213138"
        ],
        [
         "3",
         "-9214033164510198912",
         "8821538311fffff",
         "8821538317fffff",
         "51.0985433",
         "71.4057889",
         "51.0976468",
         "71.4125806"
        ],
        [
         "4",
         "-9212938812549517684",
         "8821538317fffff",
         "8821538069fffff",
         "51.0977033",
         "71.4119383",
         "51.0944483",
         "71.4240333"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>randomized_id</th>\n",
       "      <th>start_cell</th>\n",
       "      <th>end_cell</th>\n",
       "      <th>start_lat</th>\n",
       "      <th>start_lng</th>\n",
       "      <th>end_lat</th>\n",
       "      <th>end_lng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-9221304899272910788</td>\n",
       "      <td>8821538333fffff</td>\n",
       "      <td>8821538317fffff</td>\n",
       "      <td>51.082958</td>\n",
       "      <td>71.422355</td>\n",
       "      <td>51.094996</td>\n",
       "      <td>71.416271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-9217374206810770265</td>\n",
       "      <td>882153833bfffff</td>\n",
       "      <td>8821538331fffff</td>\n",
       "      <td>51.088950</td>\n",
       "      <td>71.402459</td>\n",
       "      <td>51.082103</td>\n",
       "      <td>71.400054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-9214548556609186054</td>\n",
       "      <td>8821538333fffff</td>\n",
       "      <td>8821538333fffff</td>\n",
       "      <td>51.079424</td>\n",
       "      <td>71.421915</td>\n",
       "      <td>51.079512</td>\n",
       "      <td>71.421314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-9214033164510198912</td>\n",
       "      <td>8821538311fffff</td>\n",
       "      <td>8821538317fffff</td>\n",
       "      <td>51.098543</td>\n",
       "      <td>71.405789</td>\n",
       "      <td>51.097647</td>\n",
       "      <td>71.412581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-9212938812549517684</td>\n",
       "      <td>8821538317fffff</td>\n",
       "      <td>8821538069fffff</td>\n",
       "      <td>51.097703</td>\n",
       "      <td>71.411938</td>\n",
       "      <td>51.094448</td>\n",
       "      <td>71.424033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         randomized_id       start_cell         end_cell  start_lat  \\\n",
       "0 -9221304899272910788  8821538333fffff  8821538317fffff  51.082958   \n",
       "1 -9217374206810770265  882153833bfffff  8821538331fffff  51.088950   \n",
       "2 -9214548556609186054  8821538333fffff  8821538333fffff  51.079424   \n",
       "3 -9214033164510198912  8821538311fffff  8821538317fffff  51.098543   \n",
       "4 -9212938812549517684  8821538317fffff  8821538069fffff  51.097703   \n",
       "\n",
       "   start_lng    end_lat    end_lng  \n",
       "0  71.422355  51.094996  71.416271  \n",
       "1  71.402459  51.082103  71.400054  \n",
       "2  71.421915  51.079512  71.421314  \n",
       "3  71.405789  51.097647  71.412581  \n",
       "4  71.411938  51.094448  71.424033  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -------------------------------------------------------------\n",
    "# 8. Start & End Cells + OD Flows (k-anon, filtered)\n",
    "# -------------------------------------------------------------\n",
    "# For each trip, identify start and end H3 cell at PRIMARY_HEAT_RES\n",
    "res_col = f'h3_{PRIMARY_HEAT_RES}'\n",
    "if res_col not in gdf.columns:\n",
    "    raise ValueError('Primary resolution not computed.')\n",
    "trip_bounds = gdf.sort_values(['randomized_id','seq_idx']).groupby('randomized_id').agg(\n",
    "    start_cell=(res_col,'first'),\n",
    "    end_cell=(res_col,'last'),\n",
    "    start_lat=('lat','first'), start_lng=('lng','first'),\n",
    "    end_lat=('lat','last'), end_lng=('lng','last')\n",
    ").reset_index()\n",
    "# OD pairs\n",
    "od = trip_bounds.groupby(['start_cell','end_cell']).size().reset_index(name='trip_count')\n",
    "# Drop self edges\n",
    "od = od[od['start_cell'] != od['end_cell']].copy()\n",
    "# Geodesic distance (fallback to haversine_km)\n",
    "\n",
    "def _center_latlng(cell):\n",
    "    try:\n",
    "        return h3_cell_center(cell)\n",
    "    except Exception:\n",
    "        if hasattr(h3,'h3_to_geo'): return h3.h3_to_geo(cell)\n",
    "        return (np.nan,np.nan)\n",
    "\n",
    "start_centers = od['start_cell'].apply(_center_latlng)\n",
    "end_centers = od['end_cell'].apply(_center_latlng)\n",
    "od['start_lat'] = start_centers.apply(lambda x: x[0])\n",
    "od['start_lng'] = start_centers.apply(lambda x: x[1])\n",
    "od['end_lat'] = end_centers.apply(lambda x: x[0])\n",
    "od['end_lng'] = end_centers.apply(lambda x: x[1])\n",
    "\n",
    "def _dist_row(r):\n",
    "    return haversine_km(r['start_lat'], r['start_lng'], r['end_lat'], r['end_lng'])\n",
    "od['geodesic_km'] = od.apply(_dist_row, axis=1)\n",
    "# Keep edges >=1 km\n",
    "od = od[od['geodesic_km'] >= 1.0].copy()\n",
    "# Apply k-anon on trip_count\n",
    "od_public = k_suppress(od, 'trip_count', K_ANON)\n",
    "od_public = od_public.sort_values('trip_count', ascending=False)\n",
    "od_public.to_csv(os.path.join(OUTPUT_DIR,'od_public.csv'), index=False)\n",
    "print('OD table saved (filtered & suppressed) -> outputs/od_public.csv')\n",
    "trip_bounds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dcef2f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed quantiles (0.5,0.9,0.95):\n",
      "0.50     6.781900\n",
      "0.90    15.439958\n",
      "0.95    16.618267\n",
      "Name: spd, dtype: float64\n",
      "Inferred speed units: m/s\n",
      "Using stop speed threshold: 0.5 (m/s)\n",
      "Stop-like points: 241980\n",
      "Stop clusters saved -> outputs/stop_clusters.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "cluster_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "lat_mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lng_mean",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "19213073-6087-4341-8faa-48f5bf8562ff",
       "rows": [
        [
         "0",
         "0",
         "230088",
         "51.0920777553588",
         "71.41740565117279"
        ],
        [
         "1",
         "1",
         "4085",
         "51.08245421743981",
         "71.4009740851445"
        ],
        [
         "9",
         "9",
         "1362",
         "51.090627782305425",
         "71.39965997606461"
        ],
        [
         "10",
         "10",
         "1214",
         "51.088145110461284",
         "71.39673872339374"
        ],
        [
         "2",
         "2",
         "905",
         "51.089920422099446",
         "71.4331842598895"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster_id</th>\n",
       "      <th>count</th>\n",
       "      <th>lat_mean</th>\n",
       "      <th>lng_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>230088</td>\n",
       "      <td>51.092078</td>\n",
       "      <td>71.417406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4085</td>\n",
       "      <td>51.082454</td>\n",
       "      <td>71.400974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1362</td>\n",
       "      <td>51.090628</td>\n",
       "      <td>71.399660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>1214</td>\n",
       "      <td>51.088145</td>\n",
       "      <td>71.396739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>905</td>\n",
       "      <td>51.089920</td>\n",
       "      <td>71.433184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cluster_id   count   lat_mean   lng_mean\n",
       "0            0  230088  51.092078  71.417406\n",
       "1            1    4085  51.082454  71.400974\n",
       "9            9    1362  51.090628  71.399660\n",
       "10          10    1214  51.088145  71.396739\n",
       "2            2     905  51.089920  71.433184"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -------------------------------------------------------------\n",
    "# 9. Stop Detection & Clustering (DBSCAN, revised thresholds)\n",
    "# -------------------------------------------------------------\n",
    "# Speed quantiles & unit inference\n",
    "spd_series = df['spd'].dropna()\n",
    "if spd_series.empty:\n",
    "    raise ValueError('No speed data available for stop detection.')\n",
    "quantiles = spd_series.quantile([0.5, 0.9, 0.95])\n",
    "print('Speed quantiles (0.5,0.9,0.95):')\n",
    "print(quantiles)\n",
    "\n",
    "# Infer units: heuristicâ€”if 95th percentile > 70 we assume km/h; else m/s\n",
    "p95 = quantiles.loc[0.95]\n",
    "units = 'km/h' if p95 > 70 else 'm/s'\n",
    "print(f'Inferred speed units: {units}')\n",
    "\n",
    "q10 = spd_series.quantile(0.10)\n",
    "if units == 'm/s':\n",
    "    STOP_SPEED_THRESHOLD = max(q10, 0.5)\n",
    "else:  # km/h\n",
    "    STOP_SPEED_THRESHOLD = max(q10, 2.0)\n",
    "print(f'Using stop speed threshold: {STOP_SPEED_THRESHOLD} ({units})')\n",
    "\n",
    "# Select stop-like points\n",
    "if units == 'km/h' and p95 < 150:\n",
    "    # Convert to m/s for clustering logic if needed (optional)\n",
    "    # Not strictly necessary; DBSCAN uses coordinates only.\n",
    "    pass\n",
    "\n",
    "stop_points = gdf[(gdf['spd'] <= STOP_SPEED_THRESHOLD) & (~gdf['spd'].isna())].copy()\n",
    "print(f'Stop-like points: {len(stop_points)}')\n",
    "\n",
    "# Revised DBSCAN params per task: eps=40m, min_samples=20\n",
    "from sklearn.cluster import DBSCAN\n",
    "if len(stop_points) > 0:\n",
    "    coords_rad = np.radians(stop_points[['lat','lng']].values)\n",
    "    eps_rad = 40.0 / EARTH_RADIUS_M  # 40m\n",
    "    db = DBSCAN(eps=eps_rad, min_samples=20, metric='haversine').fit(coords_rad)\n",
    "    stop_points['cluster_id'] = db.labels_\n",
    "    stop_clusters = stop_points[stop_points['cluster_id']>=0].groupby('cluster_id').agg(\n",
    "        count=('cluster_id','size'),\n",
    "        lat_mean=('lat','mean'),\n",
    "        lng_mean=('lng','mean')\n",
    "    ).reset_index().sort_values('count', ascending=False)\n",
    "else:\n",
    "    stop_clusters = pd.DataFrame(columns=['cluster_id','count','lat_mean','lng_mean'])\n",
    "\n",
    "# Export top clusters\n",
    "stop_clusters.to_csv(os.path.join(OUTPUT_DIR,'stop_clusters.csv'), index=False)\n",
    "print('Stop clusters saved -> outputs/stop_clusters.csv')\n",
    "stop_clusters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea2e14e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster mode for corridors: stop_clusters\n",
      "Top OD corridors saved -> outputs/od_top.csv (updated sampling & smoothing)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "start_cluster",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "end_cluster",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "trip_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "median_length_km_est",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "heading_variance",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "median_route_coords",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "f6f4b5b0-ce07-4cb5-9e4f-0b9398ae7336",
       "rows": [
        [
         "0",
         "16",
         "16",
         "771",
         "0.646175549659631",
         "10043.231991329778",
         "[[71.42552, 51.09525], [71.42551, 51.09565], [71.42509, 51.09533], [71.42646, 51.09556], [71.42552, 51.09525], [71.42502, 51.09564], [71.42601, 51.09562], [71.4255, 51.09523], [71.42646, 51.09556], [71.42468, 51.09544]]"
        ],
        [
         "1",
         "35",
         "35",
         "328",
         "0.3739360853133119",
         "11682.989364956513",
         "[[71.4189819, 51.1010976], [71.4175334, 51.1012922], [71.4194322, 51.1010512], [71.4175344, 51.1012943]]"
        ],
        [
         "2",
         "7",
         "7",
         "327",
         "46.48373298622628",
         "9141.81772034344",
         "[[71.4060345, 51.098903], [71.4100269, 51.0940633], [71.4099272, 51.0937366], [71.4074044, 51.0982035], [71.4063463, 51.0983585], [71.408371, 51.0905336], [71.4042352, 51.0937801], [71.4081335, 51.0899427], [71.4031419, 51.0907534], [71.4082849, 51.0905632], [71.4086533, 51.0911624], [71.4057734, 51.0980125], [71.4064222, 51.0998933], [71.4053818, 51.0969679], [71.4083297, 51.0905464], [71.4095401, 51.0926985], [71.406078, 51.0993261], [71.4107479, 51.0977085], [71.4086411, 51.0980252], [71.4083543, 51.0905269], [71.4085543, 51.0911097], [71.4089608, 51.0911445], [71.4077417, 51.0899507], [71.4034503, 51.0905579], [71.4039343, 51.0929366], [71.4088829, 51.0906577], [71.4037798, 51.0925086], [71.4046972, 51.0950292], [71.4043888, 51.0942009], [71.4105389, 51.0954944], [71.4092336, 51.0918184], [71.4064345, 51.1002563], [71.4106495, 51.0958118], [71.4108219, 51.0963237], [71.4103756, 51.0977769], [71.4082984, 51.0904586], [71.403284, 51.0912801], [71.4082979, 51.0905621], [71.4031588, 51.0905981], [71.405702, 51.0977961], [71.4100797, 51.0942099], [71.4101687, 51.0944783], [71.406041, 51.0988772], [71.406195, 51.0996305], [71.4112537, 51.0973428], [71.4111675, 51.0976441], [71.4109912, 51.0966802], [71.4098617, 51.0978449], [71.4088289, 51.0911274], [71.4083733, 51.0905967], [71.4090132, 51.0913201], [71.4084334, 51.0905238], [71.4084807, 51.0907351], [71.4061284, 51.0901553], [71.4038755, 51.0904695], [71.4063591, 51.0997399], [71.4052368, 51.0966265], [71.4093253, 51.0920872], [71.41, 51.0940117], [71.405953, 51.0988911], [71.4105983, 51.0957483], [71.4092575, 51.0979303], [71.405955, 51.0986317], [71.4060108, 51.0988629], [71.4080134, 51.0981123], [71.4083467, 51.0905417], [71.4084939, 51.0909822], [71.4087178, 51.0904149], [71.40347, 51.0916837], [71.406457, 51.1000269], [71.4048397, 51.0954477], [71.4105909, 51.09572], [71.4102973, 51.0948085], [71.4059617, 51.0988317], [71.4094244, 51.0923588], [71.4099923, 51.0939667], [71.4063088, 51.0999465], [71.4107073, 51.0960095], [71.4109699, 51.0976646], [71.4068342, 51.0982826], [71.4087016, 51.091146], [71.406455, 51.1000283], [71.4084358, 51.0905213], [71.4088464, 51.0911764], [71.4089803, 51.090892], [71.4031782, 51.0909682], [71.4067023, 51.0900844], [71.4104319, 51.0951685], [71.4066857, 51.1008819], [71.4068016, 51.1012432], [71.4059617, 51.0988317], [71.4111473, 51.097043], [71.4059922, 51.0988035], [71.4087203, 51.0903128], [71.4036305, 51.0920843], [71.4085434, 51.0909417], [71.4050309, 51.0902852], [71.4084102, 51.0900062], [71.4065748, 51.100562], [71.4058351, 51.0998031], [71.4110183, 51.0976517], [71.4105983, 51.0957483], [71.4085206, 51.0905202], [71.4088237, 51.0913258], [71.4072619, 51.0900061], [71.4031449, 51.0906289], [71.4058557, 51.09831], [71.4083622, 51.090584], [71.4091241, 51.0915175], [71.4060014, 51.0990582], [71.4110183, 51.0976517], [71.4088077, 51.0911854], [71.4082562, 51.0905256], [71.4089559, 51.0911395], [71.4087666, 51.0911452], [71.409034, 51.0910768], [71.4082755, 51.0905085], [71.4061964, 51.099223], [71.4049864, 51.0958696]]"
        ],
        [
         "3",
         "24",
         "24",
         "146",
         "0.0",
         "12530.271437445592",
         "[[71.40894, 51.09177], [71.40894, 51.09177]]"
        ],
        [
         "4",
         "23",
         "23",
         "115",
         "0.2038302422140397",
         "12544.675996060338",
         "[[71.4209155, 51.0771191], [71.4221887, 51.0770324], [71.4208333, 51.0769982], [71.4209112, 51.0771675]]"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_cluster</th>\n",
       "      <th>end_cluster</th>\n",
       "      <th>trip_count</th>\n",
       "      <th>median_length_km_est</th>\n",
       "      <th>heading_variance</th>\n",
       "      <th>median_route_coords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>771</td>\n",
       "      <td>0.646176</td>\n",
       "      <td>10043.231991</td>\n",
       "      <td>[[71.42552, 51.09525], [71.42551, 51.09565], [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>328</td>\n",
       "      <td>0.373936</td>\n",
       "      <td>11682.989365</td>\n",
       "      <td>[[71.4189819, 51.1010976], [71.4175334, 51.101...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>327</td>\n",
       "      <td>46.483733</td>\n",
       "      <td>9141.817720</td>\n",
       "      <td>[[71.4060345, 51.098903], [71.4100269, 51.0940...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>146</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12530.271437</td>\n",
       "      <td>[[71.40894, 51.09177], [71.40894, 51.09177]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>115</td>\n",
       "      <td>0.203830</td>\n",
       "      <td>12544.675996</td>\n",
       "      <td>[[71.4209155, 51.0771191], [71.4221887, 51.077...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   start_cluster  end_cluster  trip_count  median_length_km_est  \\\n",
       "0             16           16         771              0.646176   \n",
       "1             35           35         328              0.373936   \n",
       "2              7            7         327             46.483733   \n",
       "3             24           24         146              0.000000   \n",
       "4             23           23         115              0.203830   \n",
       "\n",
       "   heading_variance                                median_route_coords  \n",
       "0      10043.231991  [[71.42552, 51.09525], [71.42551, 51.09565], [...  \n",
       "1      11682.989365  [[71.4189819, 51.1010976], [71.4175334, 51.101...  \n",
       "2       9141.817720  [[71.4060345, 51.098903], [71.4100269, 51.0940...  \n",
       "3      12530.271437       [[71.40894, 51.09177], [71.40894, 51.09177]]  \n",
       "4      12544.675996  [[71.4209155, 51.0771191], [71.4221887, 51.077...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -------------------------------------------------------------\n",
    "# 10. OD Graph from Start/End Clusters & Corridor Extraction (updated)\n",
    "# -------------------------------------------------------------\n",
    "# Derive start and end clusters by snapping trip start/end points to stop clusters (if available).\n",
    "# If no stop clusters, fallback to H3 cells as clusters.\n",
    "if len(stop_clusters) > 0:\n",
    "    cl_coords = stop_clusters[['lat_mean','lng_mean']].values\n",
    "    def assign_cluster(lat, lng):\n",
    "        d = np.sqrt(((cl_coords - np.array([lat,lng]))**2).sum(axis=1))\n",
    "        idx = np.argmin(d)\n",
    "        return int(stop_clusters.iloc[idx]['cluster_id'])\n",
    "    trip_bounds['start_cluster'] = trip_bounds.apply(lambda r: assign_cluster(r['start_lat'], r['start_lng']), axis=1)\n",
    "    trip_bounds['end_cluster'] = trip_bounds.apply(lambda r: assign_cluster(r['end_lat'], r['end_lng']), axis=1)\n",
    "    cluster_mode = 'stop_clusters'\n",
    "else:\n",
    "    trip_bounds['start_cluster'] = trip_bounds['start_cell']\n",
    "    trip_bounds['end_cluster'] = trip_bounds['end_cell']\n",
    "    cluster_mode = 'h3_cells'\n",
    "print(f'Cluster mode for corridors: {cluster_mode}')\n",
    "\n",
    "cluster_od = trip_bounds.groupby(['start_cluster','end_cluster']).size().reset_index(name='trip_count')\n",
    "cluster_od = cluster_od.sort_values('trip_count', ascending=False)\n",
    "# Top K for corridor modeling\n",
    "top_cluster_od = cluster_od.head(TOP_K_OD)\n",
    "\n",
    "# Build median route per top OD pair with 10-20 sampled trips (bounded by availability)\n",
    "corridor_rows = []\n",
    "for _, row in top_cluster_od.iterrows():\n",
    "    sc, ec = row['start_cluster'], row['end_cluster']\n",
    "    candidate_ids = trip_bounds[(trip_bounds['start_cluster']==sc) & (trip_bounds['end_cluster']==ec)]['randomized_id'].tolist()\n",
    "    if not candidate_ids:\n",
    "        continue\n",
    "    random.shuffle(candidate_ids)\n",
    "    sample_upper = min(len(candidate_ids), 20)\n",
    "    sample_lower = min(sample_upper, 10)\n",
    "    sample_n = random.randint(sample_lower, sample_upper)\n",
    "    sample_ids = candidate_ids[:sample_n]\n",
    "    route_coords = []\n",
    "    for tid in sample_ids:\n",
    "        tg = trip_gdf[trip_gdf['randomized_id']==tid]\n",
    "        if tg.empty: continue\n",
    "        # Prefer 20m simplified geometry\n",
    "        geom = tg.iloc[0]['geometry_simplified_20m'] if 'geometry_simplified_20m' in tg.columns else tg.iloc[0]['geometry_simplified']\n",
    "        coords = list(geom.coords)\n",
    "        route_coords.append(coords)\n",
    "    median_route = pick_median_route(route_coords)\n",
    "    # Post-simplify median route again with 20m tolerance\n",
    "    if median_route:\n",
    "        median_route = simplify_linestring(median_route, tolerance=DP_SMOOTH_TOL_DEG)\n",
    "    length_km = line_length_km(median_route) if median_route else 0\n",
    "    heading_var = heading_variance(df[df['randomized_id'].isin(sample_ids)]['bearing'].values)\n",
    "    corridor_rows.append({\n",
    "        'start_cluster': sc, 'end_cluster': ec, 'trip_count': row['trip_count'],\n",
    "        'median_length_km_est': length_km, 'heading_variance': heading_var,\n",
    "        'median_route_coords': json.dumps(median_route)\n",
    "    })\n",
    "\n",
    "corridors_df = pd.DataFrame(corridor_rows).sort_values('trip_count', ascending=False)\n",
    "corridors_df.to_csv(os.path.join(OUTPUT_DIR,'od_top.csv'), index=False)\n",
    "print('Top OD corridors saved -> outputs/od_top.csv (updated sampling & smoothing)')\n",
    "corridors_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dff39d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample trips summary saved -> outputs/sample_trips.csv (smoothed bearings)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "masked_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "num_points",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "length_km_est",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "heading_variance_smoothed",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "roughness_smoothed",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "speed_min",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "speed_max",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "speed_mean",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "a9fbb22f-4e6f-4115-9047-3e4299433a64",
       "rows": [
        [
         "0",
         "id_63d0010818",
         "194",
         "33.18271836975218",
         "31829.168722334965",
         "10.854564090942398",
         "-1.0",
         "17.86458",
         "5.999483711340206"
        ],
        [
         "1",
         "id_cb7dbea102",
         "95",
         "29.78589806782066",
         "24853.75964960858",
         "12.093350673842382",
         "2.29428",
         "17.01741",
         "8.98417705263158"
        ],
        [
         "2",
         "id_99f5b8e328",
         "52",
         "16.53588856598093",
         "30942.640381146954",
         "43.54694979439363",
         "0.96261",
         "18.18913",
         "9.087746153846153"
        ],
        [
         "3",
         "id_7087812908",
         "11",
         "0.6791209473996122",
         "24799.727870942155",
         "1060.1948726178175",
         "1.54831",
         "4.37043",
         "2.2896454545454548"
        ],
        [
         "4",
         "id_fb1bb8b2f2",
         "87",
         "34.00569671451024",
         "26598.435497763534",
         "21.179152992672616",
         "4.2156613683911503e-19",
         "17.343158721923828",
         "9.304516980569838"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>masked_id</th>\n",
       "      <th>num_points</th>\n",
       "      <th>length_km_est</th>\n",
       "      <th>heading_variance_smoothed</th>\n",
       "      <th>roughness_smoothed</th>\n",
       "      <th>speed_min</th>\n",
       "      <th>speed_max</th>\n",
       "      <th>speed_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_63d0010818</td>\n",
       "      <td>194</td>\n",
       "      <td>33.182718</td>\n",
       "      <td>31829.168722</td>\n",
       "      <td>10.854564</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>17.864580</td>\n",
       "      <td>5.999484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_cb7dbea102</td>\n",
       "      <td>95</td>\n",
       "      <td>29.785898</td>\n",
       "      <td>24853.759650</td>\n",
       "      <td>12.093351</td>\n",
       "      <td>2.294280e+00</td>\n",
       "      <td>17.017410</td>\n",
       "      <td>8.984177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_99f5b8e328</td>\n",
       "      <td>52</td>\n",
       "      <td>16.535889</td>\n",
       "      <td>30942.640381</td>\n",
       "      <td>43.546950</td>\n",
       "      <td>9.626100e-01</td>\n",
       "      <td>18.189130</td>\n",
       "      <td>9.087746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_7087812908</td>\n",
       "      <td>11</td>\n",
       "      <td>0.679121</td>\n",
       "      <td>24799.727871</td>\n",
       "      <td>1060.194873</td>\n",
       "      <td>1.548310e+00</td>\n",
       "      <td>4.370430</td>\n",
       "      <td>2.289645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_fb1bb8b2f2</td>\n",
       "      <td>87</td>\n",
       "      <td>34.005697</td>\n",
       "      <td>26598.435498</td>\n",
       "      <td>21.179153</td>\n",
       "      <td>4.215661e-19</td>\n",
       "      <td>17.343159</td>\n",
       "      <td>9.304517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       masked_id  num_points  length_km_est  heading_variance_smoothed  \\\n",
       "0  id_63d0010818         194      33.182718               31829.168722   \n",
       "1  id_cb7dbea102          95      29.785898               24853.759650   \n",
       "2  id_99f5b8e328          52      16.535889               30942.640381   \n",
       "3  id_7087812908          11       0.679121               24799.727871   \n",
       "4  id_fb1bb8b2f2          87      34.005697               26598.435498   \n",
       "\n",
       "   roughness_smoothed     speed_min  speed_max  speed_mean  \n",
       "0           10.854564 -1.000000e+00  17.864580    5.999484  \n",
       "1           12.093351  2.294280e+00  17.017410    8.984177  \n",
       "2           43.546950  9.626100e-01  18.189130    9.087746  \n",
       "3         1060.194873  1.548310e+00   4.370430    2.289645  \n",
       "4           21.179153  4.215661e-19  17.343159    9.304517  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -------------------------------------------------------------\n",
    "# 11. Sample Trajectories (Masked, smoothed bearings)\n",
    "# -------------------------------------------------------------\n",
    "all_trip_ids = trip_gdf['randomized_id'].unique().tolist()\n",
    "random.shuffle(all_trip_ids)\n",
    "sample_ids = all_trip_ids[:SAMPLE_N_TRIPS] if len(all_trip_ids) >= SAMPLE_N_TRIPS else all_trip_ids\n",
    "sample_rows = []\n",
    "\n",
    "# Helper to compute rolling median bearing\n",
    "def rolling_median_bearing(bearings, window=5):\n",
    "    s = pd.Series(bearings)\n",
    "    return list(s.rolling(window, center=True, min_periods=1).median().fillna(method='bfill').fillna(method='ffill'))\n",
    "\n",
    "for tid in sample_ids:\n",
    "    rec = trip_gdf[trip_gdf['randomized_id']==tid]\n",
    "    if rec.empty: continue\n",
    "    geom = rec.iloc[0]['geometry_simplified_20m'] if 'geometry_simplified_20m' in rec.columns else rec.iloc[0]['geometry_simplified']\n",
    "    coords = list(geom.coords)\n",
    "    length_km = line_length_km(coords)\n",
    "    # Derive bearings pairwise\n",
    "    def _bearing(p1, p2):\n",
    "        lat1, lon1 = math.radians(p1[1]), math.radians(p1[0])\n",
    "        lat2, lon2 = math.radians(p2[1]), math.radians(p2[0])\n",
    "        dlon = lon2 - lon1\n",
    "        y = math.sin(dlon) * math.cos(lat2)\n",
    "        x = math.cos(lat1)*math.cos(lat2)*math.cos(dlon) + math.sin(lat1)*math.sin(lat2)\n",
    "        brng = math.degrees(math.atan2(y, x))\n",
    "        return (brng + 360) % 360\n",
    "    raw_bearings = [_bearing(coords[i], coords[i+1]) for i in range(len(coords)-1)] if len(coords)>1 else []\n",
    "    sm_bearings = rolling_median_bearing(raw_bearings, window=5) if raw_bearings else []\n",
    "    # Roughness uses smoothed bearings\n",
    "    turns = [abs(((sm_bearings[i+1]-sm_bearings[i]+180)%360)-180) for i in range(len(sm_bearings)-1)] if len(sm_bearings)>1 else []\n",
    "    total_turn = sum(turns)\n",
    "    roughness = (total_turn / length_km) if length_km>0 else 0.0\n",
    "    heading_var = float(np.var(sm_bearings)) if sm_bearings else np.nan\n",
    "    spd_vals = df[df['randomized_id']==tid]['spd'].dropna()\n",
    "    sample_rows.append({\n",
    "        'masked_id': mask_id(tid),\n",
    "        'num_points': rec.iloc[0]['num_points'],\n",
    "        'length_km_est': length_km,\n",
    "        'heading_variance_smoothed': heading_var,\n",
    "        'roughness_smoothed': roughness,\n",
    "        'speed_min': float(spd_vals.min()) if len(spd_vals)>0 else np.nan,\n",
    "        'speed_max': float(spd_vals.max()) if len(spd_vals)>0 else np.nan,\n",
    "        'speed_mean': float(spd_vals.mean()) if len(spd_vals)>0 else np.nan\n",
    "    })\n",
    "\n",
    "sample_trips_df = pd.DataFrame(sample_rows)\n",
    "sample_trips_df.to_csv(os.path.join(OUTPUT_DIR,'sample_trips.csv'), index=False)\n",
    "print('Sample trips summary saved -> outputs/sample_trips.csv (smoothed bearings)')\n",
    "sample_trips_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "042659a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomaly metrics (updated) saved -> outputs/anomaly_metrics.csv. Roughness top threshold=0.0168 Trips flagged=5666\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------\n",
    "# 12. Anomaly Detection (Updated: Top 1% Roughness & GPS Jumps)\n",
    "# -------------------------------------------------------------\n",
    "# This cell supersedes any earlier anomaly logic. It computes:\n",
    "#  - Per-trip geometric roughness (using 20m simplified geometry if available)\n",
    "#  - GPS jump counts (>300m instantaneous displacement)\n",
    "#  - Flags top 1% roughness (global) and any jump occurrences\n",
    "#  - Exports anomaly_metrics.csv with columns: randomized_id, roughness, gps_jumps, flags\n",
    "#  - Derives per-cell (primary H3 resolution) GPS jump counts for later visualization\n",
    "\n",
    "from math import radians, sin, cos, sqrt, atan2\n",
    "\n",
    "if 'trip_gdf' not in globals():\n",
    "    raise RuntimeError('trip_gdf not present; run trajectory construction cell before anomaly detection.')\n",
    "\n",
    "# Helper: haversine distance in km\n",
    "def _hv_km(a, b):\n",
    "    lat1, lon1 = a\n",
    "    lat2, lon2 = b\n",
    "    R = 6371.0088\n",
    "    dlat = radians(lat2 - lat1)\n",
    "    dlon = radians(lon2 - lon1)\n",
    "    sa = sin(dlat/2)**2 + cos(radians(lat1))*cos(radians(lat2))*sin(dlon/2)**2\n",
    "    c = 2*atan2(sqrt(sa), sqrt(1-sa))\n",
    "    return R*c\n",
    "\n",
    "# Ensure primary H3 index on base points for jump aggregation later\n",
    "primary_col = f'h3_{PRIMARY_HEAT_RES}'\n",
    "if primary_col not in gdf.columns:\n",
    "    gdf[primary_col] = [h3_cell_index(lat,lng,PRIMARY_HEAT_RES) for lat,lng in zip(gdf['lat'], gdf['lng'])]\n",
    "\n",
    "# Sort base dataframe for jump detection\n",
    "if 'seq_idx' in gdf.columns:\n",
    "    gdf_sorted = gdf.sort_values(['randomized_id','seq_idx']).copy()\n",
    "else:\n",
    "    gdf_sorted = gdf.sort_values(['randomized_id']).copy()\n",
    "\n",
    "# Compute per-point previous coordinates\n",
    "gdf_sorted['prev_lat'] = gdf_sorted.groupby('randomized_id')['lat'].shift(1)\n",
    "gdf_sorted['prev_lng'] = gdf_sorted.groupby('randomized_id')['lng'].shift(1)\n",
    "mask_valid_prev = gdf_sorted['prev_lat'].notna()\n",
    "\n",
    "# Distance per step (km)\n",
    "step_dist_km = []\n",
    "for lat, lng, plat, plng in zip(gdf_sorted['lat'], gdf_sorted['lng'], gdf_sorted['prev_lat'], gdf_sorted['prev_lng']):\n",
    "    if pd.isna(plat):\n",
    "        step_dist_km.append(0.0)\n",
    "    else:\n",
    "        step_dist_km.append(_hv_km((plat, plng),(lat,lng)))\n",
    "\n",
    "gdf_sorted['step_dist_km'] = step_dist_km\n",
    "# Flag GPS jumps > 0.3 km (300 m)\n",
    "JUMP_THRESHOLD_KM = 0.3\n",
    "gdf_sorted['jump_flag'] = gdf_sorted['step_dist_km'] > JUMP_THRESHOLD_KM\n",
    "\n",
    "# Aggregate jumps per trip\n",
    "trip_jump_counts = gdf_sorted.groupby('randomized_id')['jump_flag'].sum().rename('gps_jumps').reset_index()\n",
    "\n",
    "# Build anomaly metrics base using trip_gdf (one row per trip)\n",
    "rows = []\n",
    "for _, row in trip_gdf.iterrows():\n",
    "    tid = row['randomized_id']\n",
    "    # choose geometry_simplified_20m if present else geometry_simplified else geometry\n",
    "    geom = None\n",
    "    if 'geometry_simplified_20m' in row and row['geometry_simplified_20m'] is not None:\n",
    "        geom = row['geometry_simplified_20m']\n",
    "    elif 'geometry_simplified' in row and row['geometry_simplified'] is not None:\n",
    "        geom = row['geometry_simplified']\n",
    "    else:\n",
    "        geom = row['geometry']\n",
    "    coords = list(geom.coords) if geom is not None else []\n",
    "    rough = trajectory_roughness(coords) if coords else 0.0\n",
    "    rows.append({'randomized_id': tid, 'roughness': rough})\n",
    "\n",
    "anom_new = pd.DataFrame(rows)\n",
    "anom_new = anom_new.merge(trip_jump_counts, on='randomized_id', how='left')\n",
    "anom_new['gps_jumps'] = anom_new['gps_jumps'].fillna(0).astype(int)\n",
    "\n",
    "# Determine top 1% roughness threshold (guard for few trips)\n",
    "if len(anom_new) >= 50:\n",
    "    rough_thresh = anom_new['roughness'].quantile(0.99)\n",
    "elif len(anom_new) > 5:\n",
    "    rough_thresh = anom_new['roughness'].quantile(0.95)\n",
    "else:\n",
    "    rough_thresh = anom_new['roughness'].max()\n",
    "\n",
    "flags_all = []\n",
    "for _, r in anom_new.iterrows():\n",
    "    f = []\n",
    "    if r['roughness'] >= rough_thresh and rough_thresh > 0:\n",
    "        f.append('ROUGH')\n",
    "    if r['gps_jumps'] > 0:\n",
    "        f.append('JUMPS')\n",
    "    flags_all.append(';'.join(f))\n",
    "\n",
    "anom_new['flags'] = flags_all\n",
    "\n",
    "# Export with required schema\n",
    "anom_export = anom_new[['randomized_id','roughness','gps_jumps','flags']].copy()\n",
    "anom_export.to_csv(os.path.join(OUTPUT_DIR,'anomaly_metrics.csv'), index=False)\n",
    "print(f\"Anomaly metrics (updated) saved -> outputs/anomaly_metrics.csv. Roughness top threshold={rough_thresh:.4f} Trips flagged={ (anom_new['flags']!='').sum() }\")\n",
    "\n",
    "# Per-cell GPS jump aggregation (assign jump to cell of the END point of the jump step)\n",
    "# We could also assign to start; choice documented here.\n",
    "jump_points = gdf_sorted[gdf_sorted['jump_flag']].copy()\n",
    "if not jump_points.empty:\n",
    "    jump_counts_cell = jump_points.groupby(primary_col).size().reset_index(name='gps_jumps')\n",
    "else:\n",
    "    jump_counts_cell = pd.DataFrame(columns=[primary_col,'gps_jumps'])\n",
    "\n",
    "# Store global for heatmap merge\n",
    "globals()['h3_jump_counts'] = jump_counts_cell\n",
    "\n",
    "# Optionally merge into existing h3_public (non-destructive; missing cells get 0)\n",
    "if 'h3_public' in globals() and not h3_public.empty:\n",
    "    if primary_col in gdf.columns:\n",
    "        # Only modify resolution == PRIMARY_HEAT_RES copy, not original object structure integrity\n",
    "        try:\n",
    "            h3_public.loc[h3_public['resolution']==PRIMARY_HEAT_RES,'gps_jumps'] = h3_public[h3_public['resolution']==PRIMARY_HEAT_RES]['h3_index'].map(\n",
    "                dict(zip(jump_counts_cell[primary_col], jump_counts_cell['gps_jumps']))\n",
    "            ).fillna(0).astype(int)\n",
    "        except Exception as me:\n",
    "            print(f'[Warn] Could not annotate h3_public with gps_jumps: {me}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5738864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomaly metrics saved -> outputs/anomaly_metrics.csv. Flagged trajectories: 45\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "randomized_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "roughness",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "heading_var",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "length_km",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "roughness_z",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "heading_var_z",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "rough_flag",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "heading_flag",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "any_anomaly",
         "rawType": "bool",
         "type": "boolean"
        }
       ],
       "ref": "d6f0aa91-d095-4b08-b6d9-e923cc3389da",
       "rows": [
        [
         "0",
         "-9221304899272910788",
         "0.005062031977603067",
         "14175.411035778048",
         "130.02093966508662",
         "-0.7447213671539104",
         "1.0908349009720135",
         "False",
         "False",
         "False"
        ],
        [
         "1",
         "-9217374206810770265",
         "0.00362024759629968",
         "4.392627098789872",
         "34.348924492468406",
         "-1.0479976687468722",
         "-1.575721996037172",
         "False",
         "False",
         "False"
        ],
        [
         "2",
         "-9214548556609186054",
         "0.011514078723424906",
         "1682.6295429360134",
         "6.71241937666976",
         "0.612453048211048",
         "-1.2599285862988627",
         "False",
         "False",
         "False"
        ],
        [
         "3",
         "-9214033164510198912",
         "0.016808973546022503",
         "10678.613457896781",
         "51.91231846878005",
         "1.7262229987978674",
         "0.4328433981853521",
         "False",
         "False",
         "False"
        ],
        [
         "4",
         "-9212938812549517684",
         "0.008702585233025745",
         "12694.64771286459",
         "207.40848609735428",
         "0.02106132641272146",
         "0.812200046533127",
         "False",
         "False",
         "False"
        ]
       ],
       "shape": {
        "columns": 9,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>randomized_id</th>\n",
       "      <th>roughness</th>\n",
       "      <th>heading_var</th>\n",
       "      <th>length_km</th>\n",
       "      <th>roughness_z</th>\n",
       "      <th>heading_var_z</th>\n",
       "      <th>rough_flag</th>\n",
       "      <th>heading_flag</th>\n",
       "      <th>any_anomaly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-9221304899272910788</td>\n",
       "      <td>0.005062</td>\n",
       "      <td>14175.411036</td>\n",
       "      <td>130.020940</td>\n",
       "      <td>-0.744721</td>\n",
       "      <td>1.090835</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-9217374206810770265</td>\n",
       "      <td>0.003620</td>\n",
       "      <td>4.392627</td>\n",
       "      <td>34.348924</td>\n",
       "      <td>-1.047998</td>\n",
       "      <td>-1.575722</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-9214548556609186054</td>\n",
       "      <td>0.011514</td>\n",
       "      <td>1682.629543</td>\n",
       "      <td>6.712419</td>\n",
       "      <td>0.612453</td>\n",
       "      <td>-1.259929</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-9214033164510198912</td>\n",
       "      <td>0.016809</td>\n",
       "      <td>10678.613458</td>\n",
       "      <td>51.912318</td>\n",
       "      <td>1.726223</td>\n",
       "      <td>0.432843</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-9212938812549517684</td>\n",
       "      <td>0.008703</td>\n",
       "      <td>12694.647713</td>\n",
       "      <td>207.408486</td>\n",
       "      <td>0.021061</td>\n",
       "      <td>0.812200</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         randomized_id  roughness   heading_var   length_km  roughness_z  \\\n",
       "0 -9221304899272910788   0.005062  14175.411036  130.020940    -0.744721   \n",
       "1 -9217374206810770265   0.003620      4.392627   34.348924    -1.047998   \n",
       "2 -9214548556609186054   0.011514   1682.629543    6.712419     0.612453   \n",
       "3 -9214033164510198912   0.016809  10678.613458   51.912318     1.726223   \n",
       "4 -9212938812549517684   0.008703  12694.647713  207.408486     0.021061   \n",
       "\n",
       "   heading_var_z  rough_flag  heading_flag  any_anomaly  \n",
       "0       1.090835       False         False        False  \n",
       "1      -1.575722       False         False        False  \n",
       "2      -1.259929       False         False        False  \n",
       "3       0.432843       False         False        False  \n",
       "4       0.812200       False         False        False  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -------------------------------------------------------------\n",
    "# 12. Anomaly Detection (Geometry-only)\n",
    "# -------------------------------------------------------------\n",
    "anomaly_rows = []\n",
    "for idx, row in trip_gdf.iterrows():\n",
    "    coords = list(row['geometry_simplified'].coords)\n",
    "    roughness = trajectory_roughness(coords)\n",
    "    hvar = heading_variance(df[df['randomized_id']==row['randomized_id']]['bearing'].values)\n",
    "    anomaly_rows.append({'randomized_id': row['randomized_id'], 'roughness': roughness, 'heading_var': hvar, 'length_km': row['length_km_est']})\n",
    "anom_df = pd.DataFrame(anomaly_rows)\n",
    "# z-scores\n",
    "for col in ['roughness','heading_var']:\n",
    "    mu = anom_df[col].mean()\n",
    "    sd = anom_df[col].std() if anom_df[col].std() else 1.0\n",
    "    anom_df[f'{col}_z'] = (anom_df[col]-mu)/sd\n",
    "anom_df['rough_flag'] = anom_df['roughness_z'].abs() > ROUGHNESS_Z_THRESHOLD\n",
    "anom_df['heading_flag'] = anom_df['heading_var_z'].abs() > HEADING_VAR_Z_THRESHOLD\n",
    "anom_df['any_anomaly'] = anom_df[['rough_flag','heading_flag']].any(axis=1)\n",
    "num_anomalies = anom_df['any_anomaly'].sum()\n",
    "anom_df.to_csv(os.path.join(OUTPUT_DIR,'anomaly_metrics.csv'), index=False)\n",
    "print(f'Anomaly metrics saved -> outputs/anomaly_metrics.csv. Flagged trajectories: {num_anomalies}')\n",
    "anom_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8451d800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pydeck point_count heatmap saved -> outputs\\map_h3_points.html\n",
      "pydeck unique_trips heatmap saved -> outputs\\map_h3_trips.html\n",
      "[Warn] boundary failed for cell 8821538061fffff: cell_to_boundary() got an unexpected keyword argument 'geo_json'\n",
      "[Warn] boundary failed for cell 8821538065fffff: cell_to_boundary() got an unexpected keyword argument 'geo_json'\n",
      "[Warn] boundary failed for cell 8821538069fffff: cell_to_boundary() got an unexpected keyword argument 'geo_json'\n",
      "[Warn] boundary failed for cell 882153806bfffff: cell_to_boundary() got an unexpected keyword argument 'geo_json'\n",
      "[Warn] boundary failed for cell 882153806dfffff: cell_to_boundary() got an unexpected keyword argument 'geo_json'\n",
      "[Warn] boundary failed for cell 8821538159fffff: cell_to_boundary() got an unexpected keyword argument 'geo_json'\n",
      "[Warn] boundary failed for cell 8821538311fffff: cell_to_boundary() got an unexpected keyword argument 'geo_json'\n",
      "[Warn] boundary failed for cell 8821538313fffff: cell_to_boundary() got an unexpected keyword argument 'geo_json'\n",
      "[Warn] boundary failed for cell 8821538315fffff: cell_to_boundary() got an unexpected keyword argument 'geo_json'\n",
      "[Warn] boundary failed for cell 8821538317fffff: cell_to_boundary() got an unexpected keyword argument 'geo_json'\n",
      "[Warn] boundary failed for cell 8821538331fffff: cell_to_boundary() got an unexpected keyword argument 'geo_json'\n",
      "[Warn] boundary failed for cell 8821538333fffff: cell_to_boundary() got an unexpected keyword argument 'geo_json'\n",
      "[Warn] boundary failed for cell 8821538337fffff: cell_to_boundary() got an unexpected keyword argument 'geo_json'\n",
      "[Warn] boundary failed for cell 8821538339fffff: cell_to_boundary() got an unexpected keyword argument 'geo_json'\n",
      "[Warn] boundary failed for cell 882153833bfffff: cell_to_boundary() got an unexpected keyword argument 'geo_json'\n",
      "No polygons to render for static heatmaps.\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------\n",
    "# 13. Visualization: H3 Heatmap (pydeck) + Static PNG (Hardened)\n",
    "#     Extended to dual maps: point_count & unique_trips + GPS jumps tooltip\n",
    "# -------------------------------------------------------------\n",
    "import json as _json\n",
    "\n",
    "try:\n",
    "    # Defensive (re)definition of H3 wrapper helpers\n",
    "    try:\n",
    "        h3  # noqa: F821\n",
    "    except NameError:\n",
    "        import h3  # type: ignore\n",
    "\n",
    "    if 'h3_cell_center' not in globals():\n",
    "        def h3_cell_center(cell):\n",
    "            if hasattr(h3, 'h3_to_geo'):\n",
    "                return h3.h3_to_geo(cell)\n",
    "            if hasattr(h3, 'cell_to_latlng'):\n",
    "                return h3.cell_to_latlng(cell)\n",
    "            raise AttributeError('No H3 center function available')\n",
    "\n",
    "    if 'h3_cell_boundary' not in globals():\n",
    "        def h3_cell_boundary(cell):\n",
    "            if hasattr(h3, 'h3_to_geo_boundary'):\n",
    "                return h3.h3_to_geo_boundary(cell, geo_json=True)\n",
    "            if hasattr(h3, 'cell_to_boundary'):\n",
    "                return h3.cell_to_boundary(cell, geo_json=True)\n",
    "            raise AttributeError('No H3 boundary function available')\n",
    "\n",
    "    # Use integrity utilities if present\n",
    "    if 'ensure_h3_public' in globals():\n",
    "        h3_public_local = ensure_h3_public()\n",
    "    else:\n",
    "        if 'h3_public' not in globals() or 'h3_all' not in globals():\n",
    "            print('[Reconstruct:Fallback] rebuilding minimal h3_public (integrity utilities absent).')\n",
    "            if 'gdf' not in globals():\n",
    "                raise RuntimeError('gdf not available; run earlier preprocessing cells.')\n",
    "            recs = []\n",
    "            for res in H3_RES_LIST if 'H3_RES_LIST' in globals() else [PRIMARY_HEAT_RES]:\n",
    "                col = f'h3_{res}'\n",
    "                if col not in gdf.columns:\n",
    "                    gdf[col] = [h3_cell_index(lat,lng,res) for lat,lng in zip(gdf['lat'], gdf['lng'])]\n",
    "                agg = gdf.groupby(col).agg(point_count=('randomized_id','size'), unique_trips=('randomized_id','nunique')).reset_index().rename(columns={col:'h3_index'})\n",
    "                agg['resolution'] = res\n",
    "                recs.append(agg)\n",
    "            all_df = pd.concat(recs, ignore_index=True)\n",
    "            all_df['suppressed'] = all_df['point_count'] < K_ANON\n",
    "            h3_public_local = all_df[~all_df['suppressed']].copy()\n",
    "            if h3_public_local['point_count'].max() == 0:\n",
    "                h3_public_local['color_scale'] = 0.0\n",
    "            else:\n",
    "                h3_public_local['color_scale'] = (h3_public_local['point_count']/h3_public_local['point_count'].max()).clip(0,1)\n",
    "            globals()['h3_all'] = all_df\n",
    "            globals()['h3_public'] = h3_public_local\n",
    "        else:\n",
    "            h3_public_local = h3_public\n",
    "\n",
    "    # Attach gps_jumps if we have per-cell counts\n",
    "    primary_col = f'h3_{PRIMARY_HEAT_RES}'\n",
    "    if 'h3_jump_counts' in globals():\n",
    "        jc_map = dict(zip(h3_jump_counts[primary_col], h3_jump_counts['gps_jumps']))\n",
    "        # Only apply to primary resolution rows\n",
    "        if 'resolution' in h3_public_local.columns:\n",
    "            mask_primary = h3_public_local['resolution']==PRIMARY_HEAT_RES\n",
    "            h3_public_local.loc[mask_primary,'gps_jumps'] = h3_public_local.loc[mask_primary,'h3_index'].map(jc_map).fillna(0).astype(int)\n",
    "    if 'gps_jumps' not in h3_public_local.columns:\n",
    "        h3_public_local['gps_jumps'] = 0\n",
    "\n",
    "    # Ensure color_scale\n",
    "    if 'color_scale' not in h3_public_local.columns:\n",
    "        if h3_public_local['point_count'].max() == 0:\n",
    "            h3_public_local['color_scale'] = 0.0\n",
    "        else:\n",
    "            h3_public_local['color_scale'] = (h3_public_local['point_count']/h3_public_local['point_count'].max()).clip(0,1)\n",
    "\n",
    "    heat_res = PRIMARY_HEAT_RES\n",
    "    res_subset = h3_public_local[h3_public_local['resolution']==heat_res].copy()\n",
    "\n",
    "    # Add centers + fill colors for point density map\n",
    "    if HAS_PYDECK and len(res_subset)>0:\n",
    "        try:\n",
    "            res_subset['lat'] = res_subset['h3_index'].apply(lambda x: h3_cell_center(x)[0])\n",
    "            res_subset['lng'] = res_subset['h3_index'].apply(lambda x: h3_cell_center(x)[1])\n",
    "        except Exception as ce:\n",
    "            print(f'[Warn] Center computation failed: {ce}; defaulting to zeros.')\n",
    "            res_subset['lat'] = 0.0\n",
    "            res_subset['lng'] = 0.0\n",
    "        # point_count color\n",
    "        if 'color_scale' not in res_subset.columns:\n",
    "            if res_subset['point_count'].max() == 0:\n",
    "                res_subset['color_scale'] = 0.0\n",
    "            else:\n",
    "                res_subset['color_scale'] = (res_subset['point_count'] / res_subset['point_count'].max()).clip(0,1)\n",
    "        res_subset['fill_r'] = 255\n",
    "        res_subset['fill_g'] = (res_subset['color_scale']*255).astype(int).clip(0,255)\n",
    "        res_subset['fill_b'] = 100\n",
    "        res_subset['fill_a'] = 180\n",
    "        res_subset['fill_color'] = res_subset.apply(lambda r: [int(r['fill_r']), int(r['fill_g']), int(r['fill_b']), int(r['fill_a'])], axis=1)\n",
    "        tooltip_text = 'Cell: {h3_index}\\\\nPoints: {point_count}\\\\nTrips: {unique_trips}\\\\nJumps: {gps_jumps}'\n",
    "        try:\n",
    "            heat_layer = pdk.Layer(\n",
    "                'H3HexagonLayer',\n",
    "                data=res_subset,\n",
    "                get_hexagon='h3_index',\n",
    "                get_fill_color='fill_color',\n",
    "                pickable=True,\n",
    "                auto_highlight=True,\n",
    "                extruded=True,\n",
    "                elevation_scale=2,\n",
    "                get_elevation='point_count'\n",
    "            )\n",
    "            view_state = pdk.ViewState(latitude=51.169, longitude=71.449, zoom=10.5, pitch=40)\n",
    "            deck = pdk.Deck(layers=[heat_layer], initial_view_state=view_state, tooltip={'text': tooltip_text})\n",
    "            map_path = os.path.join(OUTPUT_DIR,'map_h3_points.html')\n",
    "            deck.to_html(map_path, css_background_color='white')\n",
    "            print(f'pydeck point_count heatmap saved -> {map_path}')\n",
    "        except Exception as pe:\n",
    "            print(f'[Error] pydeck point_count rendering failed: {pe}')\n",
    "\n",
    "        # Unique trips heatmap variant\n",
    "        try:\n",
    "            res_subset['color_scale_trips'] = (res_subset['unique_trips']/res_subset['unique_trips'].max()).replace([np.inf, -np.inf], 0).fillna(0)\n",
    "            res_subset['fill_color_trips'] = res_subset.apply(lambda r: [int(100 + 155*r['color_scale_trips']), int(50 + 205*(1-r['color_scale_trips'])), 150, 180], axis=1)\n",
    "            tooltip_text_trips = 'Cell: {h3_index}\\\\nTrips: {unique_trips}\\\\nPoints: {point_count}\\\\nJumps: {gps_jumps}'\n",
    "            trips_layer = pdk.Layer(\n",
    "                'H3HexagonLayer',\n",
    "                data=res_subset,\n",
    "                get_hexagon='h3_index',\n",
    "                get_fill_color='fill_color_trips',\n",
    "                pickable=True,\n",
    "                auto_highlight=True,\n",
    "                extruded=True,\n",
    "                elevation_scale=2,\n",
    "                get_elevation='unique_trips'\n",
    "            )\n",
    "            deck_trips = pdk.Deck(layers=[trips_layer], initial_view_state=view_state, tooltip={'text': tooltip_text_trips})\n",
    "            map_path_trips = os.path.join(OUTPUT_DIR,'map_h3_trips.html')\n",
    "            deck_trips.to_html(map_path_trips, css_background_color='white')\n",
    "            print(f'pydeck unique_trips heatmap saved -> {map_path_trips}')\n",
    "        except Exception as pe2:\n",
    "            print(f'[Error] pydeck unique_trips rendering failed: {pe2}')\n",
    "    else:\n",
    "        print('pydeck not available or no data; skipping interactive heatmaps.')\n",
    "\n",
    "    # Static polygon plot for point_count\n",
    "    try:\n",
    "        poly_records = []\n",
    "        for _, r in res_subset.iterrows():\n",
    "            try:\n",
    "                boundary = h3_cell_boundary(r['h3_index'])\n",
    "                if not boundary: continue\n",
    "                poly = LineString(boundary + [boundary[0]]).buffer(0)\n",
    "                poly_records.append({'geometry': poly, 'point_count': r['point_count'], 'unique_trips': r['unique_trips']})\n",
    "            except Exception as be:\n",
    "                print(f'[Warn] boundary failed for cell {r.get(\"h3_index\")}: {be}')\n",
    "        if poly_records:\n",
    "            poly_gdf = gpd.GeoDataFrame(poly_records, crs='EPSG:4326')\n",
    "            fig, ax = plt.subplots(figsize=(8,8))\n",
    "            poly_gdf.plot(column='point_count', ax=ax, legend=True, cmap='viridis', linewidth=0.1, edgecolor='grey')\n",
    "            ax.set_title('H3 Point Density (Suppression Applied)')\n",
    "            plt.axis('off')\n",
    "            png_path = os.path.join(OUTPUT_DIR,'fig_h3_points.png')\n",
    "            plt.savefig(png_path, dpi=150, bbox_inches='tight')\n",
    "            plt.close(fig)\n",
    "            print(f'Static point_count heatmap PNG saved -> {png_path}')\n",
    "            # Unique trips static\n",
    "            fig2, ax2 = plt.subplots(figsize=(8,8))\n",
    "            poly_gdf.plot(column='unique_trips', ax=ax2, legend=True, cmap='plasma', linewidth=0.1, edgecolor='grey')\n",
    "            ax2.set_title('H3 Unique Trips Density (Suppression Applied)')\n",
    "            plt.axis('off')\n",
    "            png_path2 = os.path.join(OUTPUT_DIR,'fig_h3_trips.png')\n",
    "            plt.savefig(png_path2, dpi=150, bbox_inches='tight')\n",
    "            plt.close(fig2)\n",
    "            print(f'Static unique_trips heatmap PNG saved -> {png_path2}')\n",
    "        else:\n",
    "            print('No polygons to render for static heatmaps.')\n",
    "    except Exception as sp:\n",
    "        print(f'[Error] Static polygon rendering failed: {sp}')\n",
    "\n",
    "except Exception as e:\n",
    "    print(f'[Fatal] Visualization cell encountered unrecoverable error: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7c7f95d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Integrity] h3_public OK\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------\n",
    "# 12b. (Integrity) Resilience Utilities & Self-Check\n",
    "# -------------------------------------------------------------\n",
    "import types\n",
    "\n",
    "def _df_exists(name):\n",
    "    return name in globals() and isinstance(globals()[name], (pd.DataFrame, gpd.GeoDataFrame))\n",
    "\n",
    "def ensure_trip_bounds():\n",
    "    if _df_exists('trip_bounds'): return trip_bounds\n",
    "    if not _df_exists('gdf') or 'seq_idx' not in gdf.columns:\n",
    "        raise RuntimeError('gdf/seq_idx not ready; run earlier cells.')\n",
    "    res_col = f'h3_{PRIMARY_HEAT_RES}'\n",
    "    if res_col not in gdf.columns:\n",
    "        # minimal compute\n",
    "        gdf[res_col] = [h3_cell_index(lat,lng,PRIMARY_HEAT_RES) for lat,lng in zip(gdf['lat'], gdf['lng'])]\n",
    "    tb = gdf.sort_values(['randomized_id','seq_idx']).groupby('randomized_id').agg(\n",
    "        start_cell=(res_col,'first'),\n",
    "        end_cell=(res_col,'last'),\n",
    "        start_lat=('lat','first'), start_lng=('lng','first'),\n",
    "        end_lat=('lat','last'), end_lng=('lng','last')\n",
    "    ).reset_index()\n",
    "    globals()['trip_bounds'] = tb\n",
    "    return tb\n",
    "\n",
    "def ensure_h3_public():\n",
    "    if _df_exists('h3_public') and 'color_scale' in h3_public.columns:\n",
    "        return h3_public\n",
    "    if not _df_exists('gdf'):\n",
    "        raise RuntimeError('gdf missing; cannot rebuild H3 aggregates.')\n",
    "    recs = []\n",
    "    for res in H3_RES_LIST:\n",
    "        col = f'h3_{res}'\n",
    "        if col not in gdf.columns:\n",
    "            gdf[col] = [h3_cell_index(lat,lng,res) for lat,lng in zip(gdf['lat'], gdf['lng'])]\n",
    "        agg = gdf.groupby(col).agg(point_count=('randomized_id','size'), unique_trips=('randomized_id','nunique')).reset_index().rename(columns={col:'h3_index'})\n",
    "        agg['resolution'] = res\n",
    "        recs.append(agg)\n",
    "    all_df = pd.concat(recs, ignore_index=True)\n",
    "    all_df['suppressed'] = all_df['point_count'] < K_ANON\n",
    "    pub = all_df[~all_df['suppressed']].copy()\n",
    "    if pub['point_count'].max() == 0:\n",
    "        pub['color_scale'] = 0.0\n",
    "    else:\n",
    "        pub['color_scale'] = (pub['point_count']/pub['point_count'].max()).clip(0,1)\n",
    "    globals()['h3_all'] = all_df\n",
    "    globals()['h3_public'] = pub\n",
    "    return pub\n",
    "\n",
    "def ensure_corridors():\n",
    "    if _df_exists('corridors_df'): return corridors_df\n",
    "    tb = ensure_trip_bounds()\n",
    "    if not _df_exists('trip_gdf'):\n",
    "        raise RuntimeError('trip_gdf missing; run trajectory cell.')\n",
    "    # minimal corridor build using existing logic (top K only)\n",
    "    cluster_mode = 'h3_cells'\n",
    "    if 'start_cluster' not in tb.columns:\n",
    "        tb['start_cluster'] = tb['start_cell']\n",
    "        tb['end_cluster'] = tb['end_cell']\n",
    "    cluster_od = tb.groupby(['start_cluster','end_cluster']).size().reset_index(name='trip_count').sort_values('trip_count', ascending=False)\n",
    "    top_cluster_od = cluster_od.head(TOP_K_OD)\n",
    "    rows = []\n",
    "    for _, row in top_cluster_od.iterrows():\n",
    "        sc, ec = row['start_cluster'], row['end_cluster']\n",
    "        ids = tb[(tb['start_cluster']==sc) & (tb['end_cluster']==ec)]['randomized_id'].tolist()\n",
    "        random.shuffle(ids)\n",
    "        sample_ids = ids[:ROUTE_SAMPLE_PER_OD]\n",
    "        routes = []\n",
    "        for tid in sample_ids:\n",
    "            tg = trip_gdf[trip_gdf['randomized_id']==tid]\n",
    "            if tg.empty: continue\n",
    "            coords = list(tg.iloc[0]['geometry_simplified'].coords) if 'geometry_simplified' in tg.columns else list(tg.iloc[0]['geometry'].coords)\n",
    "            routes.append(coords)\n",
    "        median_route = pick_median_route(routes)\n",
    "        length_km = line_length_km(median_route) if median_route else 0\n",
    "        heading_var = heading_variance(df[df['randomized_id'].isin(sample_ids)]['bearing'].values)\n",
    "        rows.append({\n",
    "            'start_cluster': sc, 'end_cluster': ec, 'trip_count': row['trip_count'],\n",
    "            'median_length_km_est': length_km, 'heading_variance': heading_var,\n",
    "            'median_route_coords': json.dumps(median_route)\n",
    "        })\n",
    "    cd = pd.DataFrame(rows).sort_values('trip_count', ascending=False)\n",
    "    globals()['corridors_df'] = cd\n",
    "    return cd\n",
    "\n",
    "def ensure_sample_trips():\n",
    "    if _df_exists('sample_trips_df'): return sample_trips_df\n",
    "    if not _df_exists('trip_gdf'):\n",
    "        raise RuntimeError('trip_gdf missing; run trajectory cell.')\n",
    "    tids = trip_gdf['randomized_id'].unique().tolist()\n",
    "    random.shuffle(tids)\n",
    "    sel = tids[:SAMPLE_N_TRIPS] if len(tids) >= SAMPLE_N_TRIPS else tids\n",
    "    rows = []\n",
    "    for tid in sel:\n",
    "        rec = trip_gdf[trip_gdf['randomized_id']==tid]\n",
    "        if rec.empty: continue\n",
    "        coords = list(rec.iloc[0]['geometry'].coords)\n",
    "        length_km = line_length_km(coords)\n",
    "        roughness = trajectory_roughness(coords)\n",
    "        heading_var = heading_variance(df[df['randomized_id']==tid]['bearing'].values)\n",
    "        spd_vals = df[df['randomized_id']==tid]['spd'].dropna()\n",
    "        rows.append({\n",
    "            'masked_id': mask_id(tid),\n",
    "            'num_points': rec.iloc[0].get('num_points', len(coords)),\n",
    "            'length_km_est': length_km,\n",
    "            'heading_variance': heading_var,\n",
    "            'roughness': roughness,\n",
    "            'speed_min': float(spd_vals.min()) if len(spd_vals)>0 else np.nan,\n",
    "            'speed_max': float(spd_vals.max()) if len(spd_vals)>0 else np.nan,\n",
    "            'speed_mean': float(spd_vals.mean()) if len(spd_vals)>0 else np.nan\n",
    "        })\n",
    "    sdf = pd.DataFrame(rows)\n",
    "    globals()['sample_trips_df'] = sdf\n",
    "    return sdf\n",
    "\n",
    "# Quick self-check (will not raise unless critical)\n",
    "try:\n",
    "    _ = ensure_h3_public()\n",
    "    print('[Integrity] h3_public OK')\n",
    "except Exception as e:\n",
    "    print(f'[Integrity] h3_public rebuild failed: {e}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f6aa357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start/End clusters map saved -> outputs\\map_start_end_clusters.html\n",
      "Corridors map saved -> outputs\\map_corridors.html\n",
      "Sample trips map saved -> outputs\\map_sample_trips.html\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------\n",
    "# 14. Visualization: Start/End Clusters, Corridors, Sample Trips (Hardened)\n",
    "# -------------------------------------------------------------\n",
    "try:\n",
    "    center_lat, center_lng = 51.169, 71.449\n",
    "\n",
    "    # Defensive redefinition of mask_id if earlier cell skipped\n",
    "    if 'mask_id' not in globals():\n",
    "        import hashlib\n",
    "        def mask_id(raw_id):\n",
    "            h = hashlib.sha1(str(raw_id).encode()).hexdigest()[:10]\n",
    "            return f'id_{h}'\n",
    "\n",
    "    # Rehydrate dependencies using integrity utilities if present\n",
    "    if 'ensure_trip_bounds' in globals():\n",
    "        trip_bounds_local = ensure_trip_bounds()\n",
    "    else:\n",
    "        trip_bounds_local = trip_bounds if 'trip_bounds' in globals() else None\n",
    "\n",
    "    if trip_bounds_local is None:\n",
    "        raise RuntimeError('trip_bounds unavailable and integrity utility missing.')\n",
    "\n",
    "    if 'ensure_corridors' in globals():\n",
    "        corridors_local = ensure_corridors()\n",
    "    else:\n",
    "        corridors_local = corridors_df if 'corridors_df' in globals() else pd.DataFrame(columns=['start_cluster','end_cluster','trip_count','median_route_coords','median_length_km_est'])\n",
    "\n",
    "    if 'ensure_sample_trips' in globals():\n",
    "        sample_trips_local = ensure_sample_trips()\n",
    "    else:\n",
    "        sample_trips_local = sample_trips_df if 'sample_trips_df' in globals() else pd.DataFrame()\n",
    "\n",
    "    # Guarantee cluster columns\n",
    "    if 'start_cluster' not in trip_bounds_local.columns:\n",
    "        trip_bounds_local['start_cluster'] = trip_bounds_local.get('start_cell', trip_bounds_local.columns[0])\n",
    "    if 'end_cluster' not in trip_bounds_local.columns:\n",
    "        trip_bounds_local['end_cluster'] = trip_bounds_local.get('end_cell', trip_bounds_local.columns[1])\n",
    "\n",
    "    # Start/End cluster markers\n",
    "    if HAS_FOLIUM:\n",
    "        try:\n",
    "            m_clusters = folium.Map(location=[center_lat, center_lng], zoom_start=11, tiles='cartodbpositron')\n",
    "            sc_counts = trip_bounds_local.groupby('start_cluster').size().reset_index(name='count').sort_values('count', ascending=False)\n",
    "            for _, r in sc_counts.iterrows():\n",
    "                subset = trip_bounds_local[trip_bounds_local['start_cluster']==r['start_cluster']].iloc[0]\n",
    "                folium.CircleMarker(location=[subset['start_lat'], subset['start_lng']], radius=4+math.log1p(r['count']),\n",
    "                                    popup=f'Start Cluster {r[\"start_cluster\"]} Count {r[\"count\"]}', color='blue', fill=True).add_to(m_clusters)\n",
    "            ec_counts = trip_bounds_local.groupby('end_cluster').size().reset_index(name='count').sort_values('count', ascending=False)\n",
    "            for _, r in ec_counts.iterrows():\n",
    "                subset = trip_bounds_local[trip_bounds_local['end_cluster']==r['end_cluster']].iloc[0]\n",
    "                folium.CircleMarker(location=[subset['end_lat'], subset['end_lng']], radius=4+math.log1p(r['count']),\n",
    "                                    popup=f'End Cluster {r[\"end_cluster\"]} Count {r[\"count\"]}', color='red', fill=True).add_to(m_clusters)\n",
    "            path_clusters = os.path.join(OUTPUT_DIR,'map_start_end_clusters.html')\n",
    "            m_clusters.save(path_clusters)\n",
    "            print(f'Start/End clusters map saved -> {path_clusters}')\n",
    "        except Exception as mc:\n",
    "            print(f'[Warn] Cluster map failed: {mc}')\n",
    "    else:\n",
    "        print('Folium not available; skipping start/end clusters map.')\n",
    "\n",
    "    # Corridors map\n",
    "    if HAS_FOLIUM and not corridors_local.empty:\n",
    "        try:\n",
    "            m_corridors = folium.Map(location=[center_lat, center_lng], zoom_start=11, tiles='cartodbpositron')\n",
    "            max_count = corridors_local['trip_count'].max() if 'trip_count' in corridors_local.columns and len(corridors_local)>0 else 1\n",
    "            for _, r in corridors_local.iterrows():\n",
    "                if 'median_route_coords' not in r or pd.isna(r['median_route_coords']):\n",
    "                    continue\n",
    "                coords = _json.loads(r['median_route_coords']) if isinstance(r['median_route_coords'], str) else []\n",
    "                if len(coords) < 2: continue\n",
    "                weight = 1 + 9*((r['trip_count']/max_count) if max_count else 1)\n",
    "                folium.PolyLine([(c[1], c[0]) for c in coords], color='#3186cc', weight=weight,\n",
    "                                popup=f'OD {r.get(\"start_cluster\")}->{r.get(\"end_cluster\")} Trips {r.get(\"trip_count\")} LengthKm {r.get(\"median_length_km_est\",0):.2f}').add_to(m_corridors)\n",
    "            path_corr = os.path.join(OUTPUT_DIR,'map_corridors.html')\n",
    "            m_corridors.save(path_corr)\n",
    "            print(f'Corridors map saved -> {path_corr}')\n",
    "        except Exception as co:\n",
    "            print(f'[Warn] Corridors map failed: {co}')\n",
    "    else:\n",
    "        print('Skipping corridors map (folium unavailable or empty corridors).')\n",
    "\n",
    "    # Sample trips map\n",
    "    if HAS_FOLIUM and not sample_trips_local.empty:\n",
    "        try:\n",
    "            m_samples = folium.Map(location=[center_lat, center_lng], zoom_start=11, tiles='cartodbpositron')\n",
    "            color_palette = ['#e41a1c','#377eb8','#4daf4a','#984ea3','#ff7f00']\n",
    "            ids_iter = []\n",
    "            if 'randomized_id' in trip_gdf.columns:\n",
    "                # reconstruct sample_ids from sample_trips_local masked ids if necessary\n",
    "                ids_iter = trip_gdf['randomized_id'].unique().tolist()[:len(sample_trips_local)]\n",
    "            for i, tid in enumerate(ids_iter):\n",
    "                tg = trip_gdf[trip_gdf['randomized_id']==tid]\n",
    "                if tg.empty: continue\n",
    "                if 'geometry_simplified' in tg.columns:\n",
    "                    coords = list(tg.iloc[0]['geometry_simplified'].coords)\n",
    "                else:\n",
    "                    coords = list(tg.iloc[0]['geometry'].coords)\n",
    "                folium.PolyLine([(c[1], c[0]) for c in coords], color=color_palette[i%len(color_palette)], weight=3,\n",
    "                                popup=mask_id(tid)).add_to(m_samples)\n",
    "            path_samples = os.path.join(OUTPUT_DIR,'map_sample_trips.html')\n",
    "            m_samples.save(path_samples)\n",
    "            print(f'Sample trips map saved -> {path_samples}')\n",
    "        except Exception as sm:\n",
    "            print(f'[Warn] Sample trips map failed: {sm}')\n",
    "    else:\n",
    "        print('Skipping sample trips map (folium unavailable or no samples).')\n",
    "\n",
    "except Exception as e:\n",
    "    print(f'[Fatal] Visualization (clusters/corridors/sample trips) error: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3bc5c04a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top H3 cells (by unique trips):\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "h3_index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "point_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "unique_trips",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "5e0e1308-2e8f-48ed-a17e-96e23401e105",
       "rows": [
        [
         "6",
         "8821538069fffff",
         "232469",
         "4169"
        ],
        [
         "13",
         "8821538317fffff",
         "193511",
         "3680"
        ],
        [
         "10",
         "8821538311fffff",
         "55589",
         "3228"
        ],
        [
         "8",
         "882153806dfffff",
         "165024",
         "2860"
        ],
        [
         "15",
         "8821538333fffff",
         "121707",
         "2617"
        ],
        [
         "18",
         "882153833bfffff",
         "176135",
         "2606"
        ],
        [
         "14",
         "8821538331fffff",
         "58032",
         "2204"
        ],
        [
         "11",
         "8821538313fffff",
         "47295",
         "1961"
        ],
        [
         "4",
         "8821538061fffff",
         "40462",
         "1948"
        ],
        [
         "12",
         "8821538315fffff",
         "31969",
         "1864"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>h3_index</th>\n",
       "      <th>point_count</th>\n",
       "      <th>unique_trips</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8821538069fffff</td>\n",
       "      <td>232469</td>\n",
       "      <td>4169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>8821538317fffff</td>\n",
       "      <td>193511</td>\n",
       "      <td>3680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8821538311fffff</td>\n",
       "      <td>55589</td>\n",
       "      <td>3228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>882153806dfffff</td>\n",
       "      <td>165024</td>\n",
       "      <td>2860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8821538333fffff</td>\n",
       "      <td>121707</td>\n",
       "      <td>2617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>882153833bfffff</td>\n",
       "      <td>176135</td>\n",
       "      <td>2606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8821538331fffff</td>\n",
       "      <td>58032</td>\n",
       "      <td>2204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8821538313fffff</td>\n",
       "      <td>47295</td>\n",
       "      <td>1961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8821538061fffff</td>\n",
       "      <td>40462</td>\n",
       "      <td>1948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8821538315fffff</td>\n",
       "      <td>31969</td>\n",
       "      <td>1864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           h3_index  point_count  unique_trips\n",
       "6   8821538069fffff       232469          4169\n",
       "13  8821538317fffff       193511          3680\n",
       "10  8821538311fffff        55589          3228\n",
       "8   882153806dfffff       165024          2860\n",
       "15  8821538333fffff       121707          2617\n",
       "18  882153833bfffff       176135          2606\n",
       "14  8821538331fffff        58032          2204\n",
       "11  8821538313fffff        47295          1961\n",
       "4   8821538061fffff        40462          1948\n",
       "12  8821538315fffff        31969          1864"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Start Clusters:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "start_cluster",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "trip_count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "11fc337d-5318-4a65-b0ae-76b706711d2c",
       "rows": [
        [
         "16",
         "16",
         "1349"
        ],
        [
         "7",
         "7",
         "872"
        ],
        [
         "35",
         "35",
         "651"
        ],
        [
         "19",
         "19",
         "394"
        ],
        [
         "23",
         "23",
         "378"
        ],
        [
         "27",
         "27",
         "359"
        ],
        [
         "1",
         "1",
         "319"
        ],
        [
         "29",
         "29",
         "296"
        ],
        [
         "24",
         "24",
         "255"
        ],
        [
         "21",
         "21",
         "183"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_cluster</th>\n",
       "      <th>trip_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>1349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    start_cluster  trip_count\n",
       "16             16        1349\n",
       "7               7         872\n",
       "35             35         651\n",
       "19             19         394\n",
       "23             23         378\n",
       "27             27         359\n",
       "1               1         319\n",
       "29             29         296\n",
       "24             24         255\n",
       "21             21         183"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top End Clusters:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "end_cluster",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "trip_count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "3cc9ba1b-2e86-434c-9c7a-bc03b4cdbda0",
       "rows": [
        [
         "15",
         "16",
         "1597"
        ],
        [
         "7",
         "7",
         "682"
        ],
        [
         "34",
         "35",
         "529"
        ],
        [
         "23",
         "24",
         "369"
        ],
        [
         "21",
         "22",
         "353"
        ],
        [
         "28",
         "29",
         "304"
        ],
        [
         "18",
         "19",
         "278"
        ],
        [
         "22",
         "23",
         "268"
        ],
        [
         "26",
         "27",
         "267"
        ],
        [
         "1",
         "1",
         "263"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>end_cluster</th>\n",
       "      <th>trip_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    end_cluster  trip_count\n",
       "15           16        1597\n",
       "7             7         682\n",
       "34           35         529\n",
       "23           24         369\n",
       "21           22         353\n",
       "28           29         304\n",
       "18           19         278\n",
       "22           23         268\n",
       "26           27         267\n",
       "1             1         263"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top OD Corridors:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "start_cluster",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "end_cluster",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "trip_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "median_length_km_est",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "c32d071e-04c8-4c11-a4c5-815ef8126fb6",
       "rows": [
        [
         "0",
         "16",
         "16",
         "771",
         "0.646175549659631"
        ],
        [
         "1",
         "35",
         "35",
         "328",
         "0.3739360853133119"
        ],
        [
         "2",
         "7",
         "7",
         "327",
         "46.48373298622628"
        ],
        [
         "3",
         "24",
         "24",
         "146",
         "0.0"
        ],
        [
         "4",
         "23",
         "23",
         "115",
         "0.2038302422140397"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_cluster</th>\n",
       "      <th>end_cluster</th>\n",
       "      <th>trip_count</th>\n",
       "      <th>median_length_km_est</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>771</td>\n",
       "      <td>0.646176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>328</td>\n",
       "      <td>0.373936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>327</td>\n",
       "      <td>46.483733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>146</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>115</td>\n",
       "      <td>0.203830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   start_cluster  end_cluster  trip_count  median_length_km_est\n",
       "0             16           16         771              0.646176\n",
       "1             35           35         328              0.373936\n",
       "2              7            7         327             46.483733\n",
       "3             24           24         146              0.000000\n",
       "4             23           23         115              0.203830"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of cells suppressed (primary res 8): 0.00%\n",
      "Flagged rough/heading anomaly trajectories: 45\n",
      "\n",
      "### What this dataset enables (No-Timestamp Context)\n",
      "- Demand heat & spatial intensity via H3 cell counts (ride/trip density).\n",
      "- Candidate pickup/drop hotspots (stop clusters) for repositioning & infrastructure.\n",
      "- Origin-Destination corridors for planning optimized shuttle/dispatch routes.\n",
      "- Route geometry variability & anomaly cues (zig-zag / roughness) highlight potential map errors, GPS noise zones, or safety review areas.\n",
      "- Simplified representative (\"median\") routes for top OD pairs assisting navigation template generation.\n",
      "\n",
      "### Key Limitations\n",
      "- No temporal metrics: cannot compute travel time, dwell time, speed validation over distance, or peak-hour patterns.\n",
      "- Speed column accepted as-is (cannot verify with segment distance/time).\n",
      "- No dwell threshold confidence: stop detection purely speed-based.\n",
      "\n",
      "Summary markdown saved -> outputs/summary_usable_cases.md\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------\n",
    "# 15. Metrics & Usable Cases Summary\n",
    "# -------------------------------------------------------------\n",
    "top_cells = h3_public[h3_public['resolution']==PRIMARY_HEAT_RES].sort_values('unique_trips', ascending=False).head(10)\n",
    "print('Top H3 cells (by unique trips):')\n",
    "display(top_cells[['h3_index','point_count','unique_trips']])\n",
    "\n",
    "# Top start & end clusters\n",
    "if 'start_cluster' in trip_bounds.columns:\n",
    "    start_cluster_counts = trip_bounds.groupby('start_cluster').size().reset_index(name='trip_count').sort_values('trip_count', ascending=False).head(10)\n",
    "    end_cluster_counts = trip_bounds.groupby('end_cluster').size().reset_index(name='trip_count').sort_values('trip_count', ascending=False).head(10)\n",
    "    print('Top Start Clusters:')\n",
    "    display(start_cluster_counts)\n",
    "    print('Top End Clusters:')\n",
    "    display(end_cluster_counts)\n",
    "\n",
    "print('Top OD Corridors:')\n",
    "display(corridors_df[['start_cluster','end_cluster','trip_count','median_length_km_est']].head(TOP_K_OD))\n",
    "\n",
    "# % suppressed at primary res\n",
    "res_all = h3_all[h3_all['resolution']==PRIMARY_HEAT_RES]\n",
    "sup_pct_primary = 100.0*res_all['suppressed'].mean()\n",
    "print(f'% of cells suppressed (primary res {PRIMARY_HEAT_RES}): {sup_pct_primary:.2f}%')\n",
    "anom_count = pd.read_csv(os.path.join(OUTPUT_DIR,'anomaly_metrics.csv'))['any_anomaly'].sum()\n",
    "print(f'Flagged rough/heading anomaly trajectories: {anom_count}')\n",
    "\n",
    "# Markdown style summary\n",
    "usable_cases_md = f'''\n",
    "### What this dataset enables (No-Timestamp Context)\n",
    "- Demand heat & spatial intensity via H3 cell counts (ride/trip density).\n",
    "- Candidate pickup/drop hotspots (stop clusters) for repositioning & infrastructure.\n",
    "- Origin-Destination corridors for planning optimized shuttle/dispatch routes.\n",
    "- Route geometry variability & anomaly cues (zig-zag / roughness) highlight potential map errors, GPS noise zones, or safety review areas.\n",
    "- Simplified representative (\"median\") routes for top OD pairs assisting navigation template generation.\n",
    "\n",
    "### Key Limitations\n",
    "- No temporal metrics: cannot compute travel time, dwell time, speed validation over distance, or peak-hour patterns.\n",
    "- Speed column accepted as-is (cannot verify with segment distance/time).\n",
    "- No dwell threshold confidence: stop detection purely speed-based.\n",
    "'''\n",
    "print(usable_cases_md)\n",
    "with open(os.path.join(OUTPUT_DIR,'summary_usable_cases.md'),'w', encoding='utf-8') as f:\n",
    "    f.write(usable_cases_md)\n",
    "print('Summary markdown saved -> outputs/summary_usable_cases.md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5543dc9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anomaly_metrics.csv\n",
      "config_snapshot.json\n",
      "fig_distributions.png\n",
      "h3_aggregates.csv\n",
      "h3_aggregates_raw.csv\n",
      "map_corridors.html\n",
      "map_h3_heat.html\n",
      "map_h3_points.html\n",
      "map_h3_trips.html\n",
      "map_sample_trips.html\n",
      "map_start_end_clusters.html\n",
      "od_public.csv\n",
      "od_top.csv\n",
      "sample_trips.csv\n",
      "stop_clusters.csv\n",
      "summary_usable_cases.md\n",
      "Notebook complete. All artifacts written to outputs/.\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------\n",
    "# 16. Outputs Inventory\n",
    "# -------------------------------------------------------------\n",
    "for fn in sorted(os.listdir(OUTPUT_DIR)):\n",
    "    print(fn)\n",
    "print('Notebook complete. All artifacts written to outputs/.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
